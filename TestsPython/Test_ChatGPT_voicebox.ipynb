{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d93c77f9",
   "metadata": {},
   "source": [
    "# Converting Bayesi from Matlab to Python\n",
    "## Using Chat GPT\n",
    "\n",
    "Import all of the required libraries here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c54c1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.stats import norm, logistic, norm\n",
    "from scipy.special import ndtri, expit, erf, erfinv, erfc, erfcinv\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c31b2",
   "metadata": {},
   "source": [
    "### v_psychofunc\n",
    "Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64d05daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_psychofunc(m=None, q=None, x=None, r=None):\n",
    "    # V_PSYCHOFUNC Calculate psychometric functions: trial success probability versus SNR\n",
    "\n",
    "    # Usage: p=v_psychofunc('',q,x)      % calculate probabilities\n",
    "    #        b=v_psychofunc('r',q,x)     % generate boolean variables with success prob p\n",
    "    #        p=v_psychofunc(m,q,x,r)     % Calculate likelihoods for observations r\n",
    "    #        x=v_psychofunc([m 'i'],q,p) % Calculate inverse\n",
    "\n",
    "    # Inputs:\n",
    "    #         m        mode string [may be omitted if not required]\n",
    "    #                   'n'   do not normalize likelihoods\n",
    "    #                   'f'   do not squeeze output arrays to remove singleton dimensions\n",
    "    #                   'i'   calculate inverse function\n",
    "    #                   'r'   calculate binary random variables with probability p\n",
    "    #                   ['s'   calculate sweet points for threshold and slope]\n",
    "    #                   ['d'   calculate partial derivatives with respect to q(1:5)]\n",
    "    #                   'g'   plot graph\n",
    "    #                   'G'   plot image\n",
    "    #                   'c'   include colourbar\n",
    "    #         q        model parameters. Either a column vector with a single model,\n",
    "    #                  a matrix with one model per column or a cell array with multiple values for\n",
    "    #                  some or all of the parameters\n",
    "    #                   1  probability at threshold [0.5]\n",
    "    #                   2  threshhold [0 dB]\n",
    "    #                   3  slope at threshold [0.1 prob/dB ]\n",
    "    #                   4  miss or lapse probability [0]\n",
    "    #                   5  guess probability   [0]\n",
    "    #                   6  psychometric function type [1]\n",
    "    #                       1 = logistic\n",
    "    #                       2 = cumulative Gaussian\n",
    "    #                       3 = Weibull\n",
    "    #                       [4 = reversed Weibull]\n",
    "    #                       [5 = Gumbell]\n",
    "    #                       [6 = reversed Gumbell]\n",
    "    #         x        vector of SNR values\n",
    "    #         r        test results (0 or 1) corresponding to x\n",
    "    #         p        vector of probabilities\n",
    "\n",
    "    # Outputs:\n",
    "    #         p        array of probabilities or random variates ('r' option).\n",
    "    #                  p is a squeezed 7-dimensional array\n",
    "    #                  whose dimensions correspond to x followed by the 6 model parameter entries.\n",
    "    #                  if q is a cell array, singleton dimensions are removed unless the 'f' option is given.\n",
    "    #         x        Inverse function gives SNR, x, as a function of p\n",
    "    #         b        array of boolean variables\n",
    "\n",
    "    # first sort out input arguments\n",
    "    minp = 0.01  # minimum probability to use for inverse function by default\n",
    "    qq = np.array([0.5, 0, 0.1, 0, 0, 1]).reshape(-1, 1)  # default values for q\n",
    "    \n",
    "    if r is None:\n",
    "        r = np.array([])\n",
    "        if x is None:\n",
    "            x = np.array([])\n",
    "            if q is None:\n",
    "                q = np.array([])\n",
    "                if m is None:\n",
    "                    m = ''\n",
    "                    nargin = 0\n",
    "                nargin = 1\n",
    "            nargin = 2\n",
    "        nargin = 3\n",
    "    else:\n",
    "        nargin=4\n",
    "        \n",
    "    if not isinstance(m, str):  # mode argument is optional\n",
    "        r = x\n",
    "        x = q\n",
    "        q = m\n",
    "        m = ''\n",
    "        \n",
    "    sq = q.shape\n",
    "    ckmod = 0\n",
    "\n",
    "    if isinstance(q, list):  # Check if q is a list/cell\n",
    "        nq = np.ones(6, dtype=int)\n",
    "        qax = [0] + qq.tolist()  # Used for plotting\n",
    "        for i in range(min(len(q), 6)):\n",
    "            nq[i] = len(q[i])\n",
    "            if nq[i] >= 1:\n",
    "                nr = qq.shape[1]\n",
    "                qax.append(q[i])\n",
    "                if i <= 4:  # Do not replicate for multiple models\n",
    "                    qq = np.tile(qq, (1, nq[i]))\n",
    "                    qq[i, :] = np.reshape(np.tile(q[i][:], (nr, 1)), (1, nr * nq[i]))\n",
    "                else:\n",
    "                    qq[i, :] = np.tile(q[i][0], (1, nr))\n",
    "        nq = np.maximum(nq, 1)\n",
    "        nmod = nq[5]\n",
    "        if nmod > 1:  # List of models to use\n",
    "            modlist = q[5]\n",
    "        else:\n",
    "            modlist = qq[5, 0]  # Default model\n",
    "    else:\n",
    "        if len(sq)==1:\n",
    "            nq=0\n",
    "        else:\n",
    "            nq = sq[1]\n",
    "            \n",
    "        if nq:\n",
    "            ql = np.tile(qq, (1, nq))\n",
    "            ql[:sq[0], :] = q\n",
    "        else:\n",
    "            ql = qq\n",
    "            nq = 1\n",
    "        modlist = np.unique(ql[5, :])\n",
    "        nmod = len(modlist)\n",
    "        ckmod = nmod > 1  # Need to check model list\n",
    "        qq = ql\n",
    "\n",
    "    nx = x.shape[0]\n",
    "    npt = 50  # number of points\n",
    "    if 'i' in m:  # doing inverse\n",
    "        if not nx:\n",
    "            nx = npt\n",
    "            xlim = np.dot((np.max(qq[4, :]), 1 - np.max(qq[3, :])),np.array([[1 - minp, minp], [minp, 1 - minp]]))\n",
    "            x = np.linspace(xlim[0], xlim[1], nx)[:, None]\n",
    "        p = np.zeros((nx, nq))  # space for SNRs\n",
    "        ia = 0\n",
    "        for i in range(nmod):  # loop for each model type\n",
    "            mod = modlist[i]\n",
    "            if ckmod:\n",
    "                qq = ql[:, ql[5, :] == mod]\n",
    "            pscale = 1 - qq[3, :] - qq[4, :]\n",
    "            pstd = (qq[0, :] - qq[4, :]) / pscale  # prob target compensating for miss and lapse probs\n",
    "            sstd = qq[2, :] / pscale  # slope compensating for miss and lapse probs\n",
    "            px = x * (pscale**(-1)) - qq[4, :] / pscale  # adjust for miss and lapse probs\n",
    "            if mod == 1:\n",
    "                beta = sstd / (pstd * (1 - pstd))\n",
    "                px = np.tile(qq[1, :] + np.log((1 - pstd) / pstd) / beta, (nx, 1)) - np.log(px ** (-1) - 1) * np.tile(beta ** (-1), (nx, 1))\n",
    "            elif mod == 2:  # cumulative Gaussian function\n",
    "                xtstd = -erfcinv(2 * pstd) * np.sqrt(2)  # x position of target in std measure\n",
    "                sig = norm.pdf(xtstd)/sstd\n",
    "                px = qq[1,:]-sig*xtstd-sig*erfcinv(2 * px) * np.sqrt(2)\n",
    "            elif mod == 3:\n",
    "                wlog = np.log(1 - pstd)\n",
    "                kbeta = sstd / ((pstd - 1) * wlog)\n",
    "                alpha = qq[1, :] - np.log(-wlog) / kbeta\n",
    "                px = np.tile(alpha, (nx, 1)) + np.log(-np.log(1 - px)) * np.tile(kbeta ** (-1), (nx, 1))\n",
    "            else:\n",
    "                raise ValueError('Invalid psychometric model index')\n",
    "            if ckmod:\n",
    "                p[:, ql[5, :] == mod] = px\n",
    "            else:\n",
    "                ib = ia + np.prod(p.shape) // nmod\n",
    "                p[ia:ib] = px\n",
    "                ia = ib\n",
    "    else:\n",
    "        if not nx:\n",
    "            ef = 2  # expansion factor\n",
    "            nx = npt\n",
    "            x = np.linspace(np.min(qq[1, :] - ef * (qq[0, :] - qq[4, :]) / qq[2, :]),\n",
    "                            np.max(qq[1, :] + ef * (1 - qq[0, :] - qq[3, :]) / qq[2, :]), nx)\n",
    "            x = np.reshape(x, (nx, 1))\n",
    "        p = np.zeros((nx, nq))  # space for probabilities\n",
    "        ia = 0\n",
    "        for i in range(nmod):  # loop for each model type\n",
    "            mod = modlist[i]\n",
    "            if ckmod:\n",
    "                qq = ql[:, ql[5, :] == mod]\n",
    "            pscale = 1 - qq[3, :] - qq[4, :]  # prob range excluding miss and lapse probs\n",
    "            pstd = (qq[0, :] - qq[4, :]) / pscale  # prob target compensating for miss and lapse probs\n",
    "            sstd = qq[2, :] / pscale  # slope compensating for miss and lapse probs\n",
    "            if mod == 1:  # logistic function\n",
    "                beta = sstd / (pstd * (1 - pstd))\n",
    "                px = (1+np.exp(beta * qq[1, :] + np.log((1 - pstd) / pstd) - beta*x))**(-1)\n",
    "            elif mod == 2:  # cumulative Gaussian function\n",
    "                xtstd = -erfcinv(2 * pstd) * np.sqrt(2)  # x position of target in std measure\n",
    "                sigi = sstd / norm.pdf(xtstd)\n",
    "                px = 0.5 * (1 + erf((sigi*x - qq[1, :] * sigi + xtstd) / np.sqrt(2)))\n",
    "            elif mod == 3:\n",
    "                wlog = np.log(1 - pstd)\n",
    "                kbeta = sstd / ((pstd - 1) * wlog)\n",
    "                alpha = qq[1, :] - np.log(-wlog) / kbeta\n",
    "                px = 1 - np.exp(-np.exp(kbeta*x - alpha * kbeta))\n",
    "            else:\n",
    "                raise ValueError('Invalid psychometric model index')\n",
    "            px = np.reshape(qq[4, :], (nq,1)) + np.reshape(pscale, (nq,1)) * px  # adjust for miss and lapse probs\n",
    "            if ckmod:\n",
    "                p[:, ql[5, :] == mod] = px\n",
    "            else:\n",
    "                ib = ia + np.prod(p.shape) // nmod\n",
    "                p[ia:ib] = px\n",
    "                ia = ib\n",
    "        if np.prod(r.shape):\n",
    "            mk = r.flatten() == 0\n",
    "            p[mk, :] = 1 - p[mk, :]  # invert probability for results that are zero\n",
    "            if nx > 1:\n",
    "                if 'n' in m:\n",
    "                    p = np.prod(p, axis=0)\n",
    "                else:\n",
    "                    p = np.sum(np.log(p), axis=0)\n",
    "                    p = np.exp(p - np.max(p))\n",
    "                    p = p / np.sum(p)  # normalize to equal 1\n",
    "                nx = 1\n",
    "                \n",
    "    pg = p.copy() # save unsqueezed p for plotting\n",
    "\n",
    "    if 'f' not in m and isinstance(q, list): # remove all singleton dimensions\n",
    "        szp = np.shape(p)\n",
    "        szq = szp[szp > 1]\n",
    "        szq = np.append(szq, np.ones(max(0, 2 - np.size(szq))))\n",
    "        p = np.reshape(p, szq)\n",
    "\n",
    "    if 'r' in m and 'i' not in m:\n",
    "        p = np.random.rand(*np.shape(p)) < p\n",
    "\n",
    "    if 'g' in m.lower():\n",
    "        plt.clf()\n",
    "        szp = [nx, nq]\n",
    "        czp = sum(i > 1 for i in szp)\n",
    "        if czp > 0: # check if there is anything to plot\n",
    "            if isinstance(q, list):\n",
    "                axlab = ['Input SNR', 'Threshold prob', 'Threshold SNR', 'Threshold slope', 'Lapse prob', 'Guess prob', 'Sigmoid type']\n",
    "                szs, izs = np.sort(szp)[::-1], np.argsort(szp)[::-1]\n",
    "                pg = np.transpose(pg, izs)\n",
    "                qax = [x]\n",
    "                if 'G' in m or czp > 2: # image\n",
    "                    ngr = np.prod(szs[2:])\n",
    "                    ncol = np.ceil(np.sqrt(ngr))\n",
    "                    nrow = np.ceil(ngr/ncol)\n",
    "                    npix = np.prod(szs[:2])\n",
    "                    ia = 0\n",
    "                    for i in range(ngr):\n",
    "                        plt.subplot(nrow, ncol, i+1)\n",
    "                        ib = ia + npix\n",
    "                        plt.imshow(np.transpose(np.reshape(pg[ia:ib], szs[:2]), (1, 0)))\n",
    "                        plt.axis('xy')\n",
    "                        if 'c' in m:\n",
    "                            plt.colorbar()\n",
    "                        if nrow*ncol-i < ncol:\n",
    "                            plt.xlabel(axlab[izs[0]])\n",
    "                        if (i % ncol) == 0:\n",
    "                            plt.ylabel(axlab[izs[1]])\n",
    "                        ia = ib\n",
    "                else: # graph\n",
    "                    plt.plot(qax[izs[0]], np.reshape(np.transpose(pg, izs), szs[:2]), '-')\n",
    "                    plt.xlabel(axlab[izs[0]])\n",
    "            else:\n",
    "                if 'G' in m: # image\n",
    "                    plt.imshow(pg.T)\n",
    "                    if 'c' in m:\n",
    "                        plt.colorbar()\n",
    "                    plt.xlabel('Input SNR (dB)')\n",
    "                    plt.ylabel('Model Index')\n",
    "#                     plt.xlim(-1, 1)\n",
    "#                     plt.ylim(-0.5,1.5)\n",
    "                else: # graph\n",
    "                    if nx >= nq:\n",
    "                        plt.plot(x, pg, '-')\n",
    "                        plt.xlabel('Input SNR (dB)')\n",
    "                    else:\n",
    "                        plt.plot(range(nq), pg.transpose(), '-')\n",
    "                        plt.xlabel('Model Index')\n",
    "\n",
    "    return p, x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b598eb48",
   "metadata": {},
   "source": [
    "**Test the function here**\n",
    "\n",
    "_To do_:\n",
    "* define test cases to test\n",
    "* test and validate all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99c4fca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q = np.array([[0.5], [10], [0.1], [0.1], [0], [3]])\n",
    "v_psychofunc('gc',q)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91732d5",
   "metadata": {},
   "source": [
    "### v_quadpeak\n",
    "Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e422d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_quadpeak(z):\n",
    "    global wz, a\n",
    "    sz = np.array(z.shape) # size of input array\n",
    "    psz = np.prod(sz) # number of elements in input array\n",
    "    dz = np.size(sz) # number of input dimensions\n",
    "    mz = np.where(sz > 1)[0] # non-singleton dimension indices\n",
    "    nm = len(mz) # number of non-singleton dimensions\n",
    "    vz = sz[mz] # size of squeezed input array\n",
    "    dx = max(mz) # number of output dimensions\n",
    "    if nm == 0:\n",
    "        raise ValueError('Cannot find peak of a scalar')\n",
    "    \n",
    "    nc = int((nm + 1) * (nm + 2) / 2)\n",
    "    \n",
    "    if np.min(vz) < 3:\n",
    "        raise ValueError('Need at least 3 points in each non-singleton dimension')\n",
    "        \n",
    "    if 'wz' not in globals():\n",
    "        wz = np.empty([]);\n",
    "\n",
    "    if wz is None or np.size(wz) != np.size(vz) or not np.all(wz == vz):\n",
    "        wz = vz.copy()\n",
    "        a = np.ones((psz, nc))\n",
    "        ix = np.arange(psz)\n",
    "        \n",
    "        for i in range(nm):\n",
    "            jx = np.floor(ix / sz[mz[i]]).astype(int)\n",
    "            a[:, i + nc - nm - 1] = 1 + ix - jx * sz[mz[i]]\n",
    "            ix = jx\n",
    "            a[:, (-1+(i+1)**2-(i+1)+2)//2:(i+1)*((i+1) + 1)//2] = a[:, nc-nm-1:i+nc-nm] * a[:,i+nc-nm-1].reshape((-1,1))\n",
    "        a = np.linalg.inv(a.T @ a) @ a.T\n",
    "    c = a @ z.ravel()\n",
    "    w = np.zeros((nm + 1, nm + 1))\n",
    "    i = np.arange(1, nc + 1)\n",
    "    j = np.floor((np.sqrt(8 * i - 7) - 1) / 2).astype(int)\n",
    "    w = w.ravel(order='F')\n",
    "    w[i+j* (2 * nm + 1 - j) // 2 - 1] = c\n",
    "    w = np.reshape(w, (nm+1, nm+1), order='F')\n",
    "    w = (w + w.T) / 2\n",
    "    \n",
    "    mr = w[:nm, :nm]\n",
    "    we = w[:nm, nm]\n",
    "    y = np.flip(-np.linalg.solve(mr, we))\n",
    "    v = y.T @ we + w[nm, nm]\n",
    "    x = np.zeros((dx+1, 1))\n",
    "    x[mz] = np.atleast_2d(y).T\n",
    "\n",
    "    m = np.zeros((dx + 2, dx + 2))\n",
    "    mz = np.append(mz,dx+1)\n",
    "    m[np.ix_(mz,mz)] = w\n",
    "    ev = np.linalg.eigvals(mr)\n",
    "    t = float((ev > 0).all()==True) - float((ev < 0).all()==True)\n",
    "\n",
    "    ze = np.zeros(sz)\n",
    "    scp = np.cumprod(np.concatenate(([1], sz[:-1])))\n",
    "    ivec = np.floor(np.tile(np.arange(psz).reshape(-1, 1), (1, dz)) / np.tile(scp, (psz, 1))).astype(int)\n",
    "    xe = np.concatenate((1 + ivec - np.tile(sz, (psz, 1)) * np.floor(ivec / np.tile(sz, (psz, 1))), np.ones((psz, 1))), axis=1)\n",
    "    ze = np.sum((xe @ m) * xe, axis=1).reshape(sz)\n",
    "    \n",
    "    return v, x, t, m, ze\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab186fd",
   "metadata": {},
   "source": [
    "### v_psychest\n",
    "\n",
    "Function definition\n",
    "\n",
    "_To do_:\n",
    "* implement robust estimates\n",
    "* implement free SNR selection\n",
    "* implement plotting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d19b53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_psycest(iq, **kwargs):\n",
    "# V_PSYCEST estimate multiple psychometric functions\n",
    "\n",
    "# Usage: (* inputs have default values; ** optional)\n",
    "#           [xx,ii,m,v]=v_psycest(-n,*modelp,*basiep,*availsnr,**logfile) % initialize n models\n",
    "#           [xx,ii,m,v]=v_psycest(i,probesnr, response, **plotopts)     % supply a trial result to v_psycest\n",
    "#   [modelp,basiep,msr]=v_psychest(0)    % output model parameters \n",
    "\n",
    "# Inputs: \n",
    "#           -n            minus the number of each model\n",
    "#           modelp(:,n)   parameters for each model [list or np.array]\n",
    "#                            1  thresh  [0.75]\n",
    "#                            2  miss [0.04]\n",
    "#                            3  guess [0.1]\n",
    "#                            4  SNR min [-20]\n",
    "#                            5  SNR max [20]\n",
    "#                            6  Slope min (over-riden if < basiep.sl) [0]\n",
    "#                            7  Slope max [0.5]\n",
    "#           basiep(:)     parameters common to all models [dict]\n",
    "#                            1  nx  number of SNR values in pdf [40]\n",
    "#                            2  ns  number of slope values in pdf [21]\n",
    "#                            3  nh  number of probe SNR values to evaluate [30]\n",
    "#                            4  cs  weighting of slope relative to SRT in cost function [1]\n",
    "#                            5  dh  minimum step size in dB for probe SNRs [0.2]\n",
    "#                            6  sl  min slope at threshold (must be >0) [0.005]\n",
    "#                            7  kp  number of std deviations of the pdfs to keep [4]\n",
    "#                            8  hg  amount to grow expected gains in ni trials [1.3]\n",
    "#                            9  cf  cost function: 1=variance, 2=v_entropy [2]\n",
    "#                           10  pm  psychometric model: 1=logistic, 2=cumulative gaussian [1]\n",
    "#                           11  lg  use log slope in pdf: 0=no, 1=yes [1]\n",
    "#                           12  pp  Number of prior standard deviations in initial semi-range [1]\n",
    "#                           13  pf  Probability floor (integrated over entire grid) [0.0001]\n",
    "#                           14  ts  Number of std devs to explore [2]\n",
    "#                           15  dp  Maximum probe SNR shift (dB) [10]\n",
    "#                           16  it  Grid interpolation threshold [0.5]\n",
    "#                           17  at  Axis change threshold [0.1]\n",
    "#                           18  la  Look 2-ahead when choosing probe [1]\n",
    "#                           19  op  Outlier probability [0.01]\n",
    "#                           20  rx  Minimum range factor per iteration [0.5]\n",
    "#           availsnr      list of available probe SNR values [np.array]\n",
    "#           logfile       log file ID\n",
    "#           i             model probed (indexing starts at 1)\n",
    "#           probesnr      probe SNR value used\n",
    "#           response      response (True or False)\n",
    "#           plotopts      plot option string: {NOT YET IMPLEMENTED}\n",
    "#                           'p' Plot pdf\n",
    "#                           'h' Plot probe history\n",
    "#                           'x' Plot expected cost function for probe SNRs\n",
    "#                           'c' Plot cost function evolution\n",
    "#\n",
    "#                    v_psycest(i,o)       % plot pdf of model i with plot options o\n",
    "#        [xx,ii,m,v,mr,vr]=v_psycest(i,o) % Determine robust outputs in addition expcluding outliers [takes longer]\n",
    "#              [p,q,msr]=psychest(0)    % output model parameters (or print them if no outputs)\n",
    "# Outputs:\n",
    "#           xx            recommended probe SNR\n",
    "#           ii            recommended model to probe next\n",
    "#           m(2,n,3)      estimated srt and slope of all models\n",
    "#                              m(:,:,1:3,n)  respectively the mean, mode (MAP) and marginal mode estimates\n",
    "#           v(3,n)        covariance matrix entries:\n",
    "#                              [var(srt) cov(srt,slope) var(slope)]'\n",
    "#           mr(2,n,3)     robust estimated srt and slope of all models\n",
    "#           vr(3,n)       robust estimated covariance matrix entries\n",
    "#           msr(:,3)      List probe snrs and results: [model probe-snr result]\n",
    "\n",
    "    global wq, xq, sq, nr, pr, qr, mq, vq, xn, hn, hfact, xz, res, nres, nresq, xmm, mq0, pq0, wfl, sqmin, LOG, mqr, vqr, nresr, xlim\n",
    "    if iq < 0: # initialization\n",
    "        # when iq<0, inputs required are:\n",
    "        # model parameters (modelp). Must be a 7x1 or (7xni) np array.\n",
    "        \n",
    "        # ---------- check kwargs ---------- #\n",
    "        if 'modelp' not in kwargs:\n",
    "            warnings.warn('No model parameters found. Using defaults')\n",
    "            x = None\n",
    "        else:\n",
    "            x = kwargs.get('modelp')\n",
    "        \n",
    "        if 'basiep' not in kwargs:\n",
    "            warnings.warn('No basie parameters found. Using defaults')\n",
    "            r = None\n",
    "        else:\n",
    "            r = kwargs.get('basiep')\n",
    "        \n",
    "        if 'availsnr' not in kwargs:\n",
    "            warnings.warn('No available snr found. Using defaults')\n",
    "            xp = None\n",
    "        else:\n",
    "            xp = kwargs.get('availsnr')\n",
    "            \n",
    "        if 'logfile' in kwargs:\n",
    "            LOG = kwargs.get('logfile')\n",
    "            with open(LOG, 'a') as f:\n",
    "                f.write(\"******************************\\n\")\n",
    "                f.write(\"psycest Initialization: {}\\n\".format(str(datetime.datetime.now())))\n",
    "                f.write(\"******************************\\n\")\n",
    "        else:\n",
    "            LOG = None\n",
    "        \n",
    "        # initialise number of models\n",
    "        ni = -iq                 # number of models\n",
    "        nres = 0                 # total number of probe-results so far\n",
    "        nresq = np.atleast_2d(np.zeros((1,ni)))    # number of probe-results for each model\n",
    "        res = np.atleast_2d(np.zeros(7))        # array for saving results [expands as needed]\n",
    "        \n",
    "        \n",
    "        # initialise model specific parameters\n",
    "        pr = np.tile([0.5, 0.04, 0.1, -20, 20, 0, 0.5], (ni, 1)).T         # default parameters\n",
    "        if x is not None:\n",
    "            if isinstance(x, list):\n",
    "                x=np.tile(x, (1, 1)).T\n",
    "            if 7 not in np.shape(x):\n",
    "                raise ValueError('Requires 7 modelp')\n",
    "            if len(np.shape(x))==1:\n",
    "                x = np.atleast_2d(x)\n",
    "            if np.shape(x)[1]==7 and np.shape(x)[0]!=7:\n",
    "                x = x.T\n",
    "            if x.shape[1] > 1:\n",
    "                if x.shape[1] > ni:\n",
    "                    raise ValueError(\"initialization parameter argument has too many columns\")\n",
    "                pr[:x.shape[0], :x.shape[1]] = x\n",
    "            else:\n",
    "                pr[:x.shape[0], :] = np.tile(x, (1, ni))\n",
    "        \n",
    "        # initialise parameters common to all models\n",
    "        nr = np.array([40, 21, 30, 1, 0.2, 0.02, 4, 1.3, 2, 1, 1, 1, 0.0001, 2, 10, 0.5, 0.1, 1, 0.01, 0.5])                      # default parameter values\n",
    "        nrf = np.array(['nx', 'ns', 'nh', 'cs', 'dh', 'sl', 'kp', 'hg', 'cf', 'pm', 'lg', 'pp', 'pf', 'ts', 'dp', 'it', 'at', 'la', 'op', 'rx']).T     # parameter field names\n",
    "        numnr = len(nr)\n",
    "        if r is not None: # replace defaults with any parameter values specified in the call\n",
    "            if isinstance(r, dict):\n",
    "                for k, v in r.items():\n",
    "                    mk = [x == k for x in nrf]\n",
    "                    if any(mk):\n",
    "                        nr[mk] = v\n",
    "            else:\n",
    "                nr[:min(numnr, len(r))] = r[:min(numnr, len(r))] # if parameters are specified as a vector, copy them across\n",
    "            nr[:3] = np.round(nr[:3])             # first three parameters must be integers\n",
    "        pr[5, :] = np.maximum(pr[5, :], nr[5])             # low limit of slope in prob/dB\n",
    "        nxq = nr[0]\n",
    "        nsq = nr[1]\n",
    "        nsxq = nxq * nsq\n",
    "        xq = np.linspace(pr[3], pr[4], int(nxq))\n",
    "\n",
    "        if nr[10]:  # if log slope\n",
    "            sqmin = np.log(nr[5])  # low limit for axis\n",
    "#             sq = np.array((np.arange(1-nsq, 1,1)*(np.log(pr[6, :]) - np.log(np.maximum(pr[5, :], nr[5])))/(nsq-1)) + np.log(pr[6, :]),ndmin=2).T\n",
    "            sq = np.outer((np.arange(1-nsq, 1,1)),(np.log(pr[6, :]) \n",
    "                                                   - np.log(np.maximum(pr[5, :], nr[5]))))/(nsq-1) + np.tile(np.log(pr[6, :]),(int(nsq),1))\n",
    "        else:\n",
    "            sqmin = nr[5].copy()  # low limit for axis\n",
    "            sq = np.array((np.arange(1-nsq, 1,1)*(pr[6, :] - np.maximum(pr[5, :], nr[5]))/(nsq-1)) + pr[6, :],ndmin=2).T\n",
    "            \n",
    "        mq0 = np.vstack((np.mean(xq, axis=0), np.mean(sq, axis=0)))  # find mean of prior\n",
    "        pq0 = -2 * nr[11]**2 * np.power(np.vstack((xq[-1, :] - xq[0, :], sq[-1, :] - sq[0, :])), -2)  # scale factor for prior distribution\n",
    "        wq = (np.tile((pq0[1, 0] * np.power((sq[:, 0] - mq0[1, 0]), 2)), (int(nxq),1)) + np.tile(pq0[0, 0] * np.power((xq[:, 0] - mq0[0, 0]), 2),(int(nsq),1)).T) # log probs of prior (same for all models)\n",
    "\n",
    "        wfl = np.log(nr[12] / nsxq)  # floor relative to peak of wq array\n",
    "        wq = np.tile(wq.ravel(), (ni,1)).T  # initialize to +-q.pp std deviations of gaussian prior\n",
    "        qr = np.zeros((5, ni))\n",
    "        \n",
    "        qr[0, :] = 1 - pr[1, :] - pr[2, :]  # prob range covered by cumulative gaussian\n",
    "        \n",
    "        \n",
    "        if np.any(qr[0, :] <= 0):\n",
    "            i = np.argmin(qr[0, :])\n",
    "            raise ValueError(f\"Model {i}: guess prob ({pr[2, i]:.2f}) + miss prob ({pr[1, i]:.2f}) is >=1\")\n",
    "        qr[1, :] = (pr[0, :] - pr[2, :])/qr[0, :]  # cumulative gaussian probability at threshold\n",
    "        if np.any(np.abs(qr[1, :] - 0.5) >= 0.5):\n",
    "            i = np.argmax(np.abs(qr[1, :] - 0.5))\n",
    "            raise ValueError(f\"Model {i}: target SRT threshold ({pr[0, i]:.2f}) must lie in the range guess prob ({pr[2, i]:.2f}) to (1-miss prob) ({1-pr[1, :]:.2f})\")\n",
    "\n",
    "        if nr[9] == 1:  # logistic model\n",
    "            qr[2,:] = np.log(qr[1,:]/(1-qr[1,:]))\n",
    "            qr[3,:] = qr[0,:]*qr[1,:]*(1-qr[1,:])\n",
    "        elif nr[9] == 2:  # cumulative gaussian model\n",
    "            qr[2,:]= -erfcinv(2 * qr[1,:]) * np.sqrt(2)\n",
    "            qr[3,:] = qr[0,:]*norm.pdf(qr[2,:])\n",
    "        else:\n",
    "            raise ValueError('Unrecognised psychometric model selection')\n",
    "\n",
    "        if nr[9] < 1 or nr[9] > 2:\n",
    "            raise ValueError('Unrecognised cost function option')\n",
    "        mq = np.tile(mq0.T, (3, 1, 1)).T  # initial means, joint mode and marginal mode all are equal\n",
    "        vq = np.vstack((np.var(xq, axis=0, ddof=0), np.zeros((1, ni)), np.var(sq, axis=0, ddof=0)))  # initial variances (actually ignores prior probs)\n",
    "        mqr = mq.copy()  # robust means and modes\n",
    "        vqr = vq.copy()  # robust variances\n",
    "        nresr = 0  # robust calculation time\n",
    "        xlim = np.vstack((-np.inf * np.ones(ni), np.inf * np.ones(ni)))  # SNR limits for outliers\n",
    "        hn = np.inf * np.ones(ni)  # very high initial cost function\n",
    "        hfact = nr[7] ** (1 / ni)  # growth factor to ensure that no model is neglected for too long\n",
    "        xn = mq0[0, :].copy()  # start at mean value\n",
    "        xmm = np.vstack((xn, xn))  # min/max of probe values for each model\n",
    "        \n",
    "        # initialise available snrs\n",
    "        if xp is not None and len(xp) > 0:\n",
    "            if xp.ndim>1:\n",
    "                xz = np.atleast_2d(xp)\n",
    "            else:\n",
    "                xz = np.tile(np.expand_dims(xp, axis=0), (ni, 1)).tolist()  # else replicate for each model\n",
    "            for i in range(ni):\n",
    "                j = np.argmin(np.abs(np.array(xz[i]) - mq0[0, i]))  # select the closest available probe to the mean\n",
    "                xn[i] = xz[i][j]\n",
    "        else:\n",
    "            xz = [None] * ni  # make empty list\n",
    "        \n",
    "    elif iq>0:\n",
    "        # iq>0 means update or plot model iq\n",
    "        \n",
    "        # first check the plotting options\n",
    "        if 'plotopts' in kwargs:\n",
    "            po = kwargs.get('plotopts')\n",
    "        else:\n",
    "            po = ''\n",
    "            \n",
    "        if 'probesnr' in kwargs:\n",
    "            x = kwargs.get('probesnr')\n",
    "        else:\n",
    "            x = None\n",
    "            \n",
    "        if 'response' in kwargs:\n",
    "            r = kwargs.get('response')\n",
    "            if isinstance(r, bool):\n",
    "                r=np.array([[(r)]])\n",
    "            elif isinstance(r, int) or isinstance(r, float):\n",
    "                r=np.array([[(r=='1')]])\n",
    "        else:\n",
    "            r = None\n",
    "                    \n",
    "        if 'robust' in kwargs:\n",
    "            robust = kwargs.get('robust')\n",
    "        else:\n",
    "            robust = False\n",
    "            \n",
    "            \n",
    "        # now get parameters of current model (iq)\n",
    "        nxq = nr[0] # number of snr values\n",
    "        nsq = nr[1] # number of slope values\n",
    "        nxh = nr[2] # number of probe-snr values\n",
    "        nsxq = nxq*nsq # size of log pdf array\n",
    "        \n",
    "        thresh = pr[0,iq-1].copy() # target probability at threshold\n",
    "        guess = pr[2,iq-1].copy() # quess rate (1/choices)\n",
    "        pscale = qr[0,iq-1].copy() # prob range left after substracting miss and guess probs\n",
    "        xtstd = qr[2,iq-1].copy() # x position of target in std measure\n",
    "\n",
    "        xqi = xq[:,iq-1] # SRT values of the pdf array\n",
    "        sqi = sq[:,iq-1] # slope (or log slope) values in PDF\n",
    "        wqi = wq[:,iq-1] # log pdf array\n",
    "        mqi = mq[:,iq-1,0] # [xe;se] means\n",
    "        vqi = vq[:,iq-1] # [xv; sxv; sv] covariance matrix\n",
    "        \n",
    "        # rescale pdfs if necessary\n",
    "        ssd = np.sqrt(vqi[2])           # std deviation of slope\n",
    "        xsd = np.sqrt(vqi[0])           # std deviation of SRT\n",
    "        # determine range of new grid\n",
    "        xqrange = xqi[-1] - xqi[0]      # range of old SRT grid\n",
    "        sqrange = sqi[-1] - sqi[0]      # range of old slope grid\n",
    "\n",
    "        if nresq[0,iq-1] < 2:               # keep old limits if nresq(iq) < 2\n",
    "            xq2lim = [xqi[0], xqi[-1]]\n",
    "            sq2lim = [sqi[0], sqi[-1]]\n",
    "        else:\n",
    "            # CHECK HERE\n",
    "            xqsemirange = max(nr[6] * xsd, 0.5 * nr[19] * xqrange)\n",
    "            xq2lim = [mqi[0] - xqsemirange, mqi[0] + xqsemirange]\n",
    "            sqsemirange = max(nr[6] * ssd, 0.5 * nr[19] * sqrange)\n",
    "            sq2lim = [max(sqmin, mqi[1] - sqsemirange), mqi[1] + sqsemirange]\n",
    "            \n",
    "            if abs(xq2lim[0] - xqi[0]) < nr[16] * xqrange:\n",
    "                xq2lim[0] = xqi[0]\n",
    "            if abs(xq2lim[1] - xqi[-1]) < nr[16] * xqrange:\n",
    "                xq2lim[1] = xqi[-1]\n",
    "\n",
    "            if abs(sq2lim[0] - sqi[0]) < nr[16] * sqrange:\n",
    "                sq2lim[0] = sqi[0]\n",
    "            if abs(sq2lim[1] - sqi[-1]) < nr[16] * sqrange:\n",
    "                sq2lim[1] = sqi[-1]\n",
    "\n",
    "        xq2 = np.linspace(xq2lim[0], xq2lim[1], int(nxq)).reshape(-1, 1) # new x axis values\n",
    "        sq2 = np.linspace(sq2lim[0], sq2lim[1], int(nsq)).reshape(-1, 1) # new s axis values\n",
    "        wqup = 2 # update flag\n",
    "\n",
    "        if xq2[0] < xqi[0] or xq2[-1] > xqi[-1] or sq2[0] < sqi[0] or sq2[-1] > sqi[-1]:\n",
    "#             if extrapolating, recalculate log-pdfs from saved data\n",
    "            if LOG:\n",
    "                print(f'N={iq}:{int(nresq[0,iq-1])}, extrapolate: x({xqi[0]:.2f},{xqi[-1]:.2f})->({xq2[0]},{xq2[-1]}) and s({sqi[0]:.2f},{sqi[-1]:.2f})->({sq2[0]},{sq2[-1]})')\n",
    "\n",
    "            wq2 = (np.tile(pq0[1,iq-1]*(sq2-mq0[1,iq-1])**2, (1,int(nxq))).T + np.tile(pq0[0,iq-1]*(xq2-mq0[0,iq-1])**2, (1,int(nsq)))).T # log probs of prior for model iq\n",
    "            ires = np.where(res[:nres,0] == iq-1)[0] # find the results for this model\n",
    "            sqis = np.exp(sq2)/qr[3,iq-1] if nr[10] else sq2/qr[3,iq-1] # inverse std dev of gaussian (proportional to slope)\n",
    "            for i in range(len(ires)):\n",
    "                j = ires[i]\n",
    "                r0 = res[j,2] == 0\n",
    "                if nr[9] == 1:\n",
    "                    wq2 = wq2 + np.log(r0 + (1 - 2*r0) * (guess + pscale * (1 + np.exp(np.multiply(sqis, xq2.T) - xtstd - np.multiply(sqis, res[j,1])))**(-1))) # P(l | r,x)\n",
    "                elif nr[9] == 2:\n",
    "                    wq2 = wq2 + np.log(r0 + (1 - 2*r0) * (guess + pscale * norm.cdf(np.multiply(sqis, res[j,1]) - np.multiply(sqis, xq2.T) + xtstd))) # P(l | r,x)\n",
    "\n",
    "        else:\n",
    "            # Turn into a normalized, clipped matrix for easy interpolation\n",
    "            wq2 = np.maximum(np.reshape(wqi, (int(nsq), int(nxq))) - np.max(wqi), wfl)\n",
    "            # Use quadratic interpolation in SRT axis\n",
    "            if ((xq2[-1] - xq2[0]) / (xqrange)) > nr[15]:\n",
    "                # If range has shrunk by < nr(16), leave the SRT axis unchanged\n",
    "                xq2 = xqi.copy()  # Copy the old SRT axis\n",
    "                wqup = 1  # Update flag\n",
    "            else:\n",
    "                # Do quadratic interpolation\n",
    "                if LOG:\n",
    "                    print(f'N={iq}:{nresq[0, iq-1]}, interpolate x: x({xqi[0]},{xqi[-1]})->({xq2[0]},{xq2[-1]})')\n",
    "                xqf = (xq2 - xqi[0]) / (xqi[1] - xqi[0])\n",
    "                xqj = np.ceil(xqf).astype(int)\n",
    "                xqf = xqj - xqf\n",
    "                xqg = 1 - xqf\n",
    "                xqh = 0.25 * xqf * xqg  # Quadratic coefficient\n",
    "\n",
    "                mask1 = (xqj <= 0) | (xqj > nxq)\n",
    "                mask2 = (xqj < 0) | (xqj >= nxq)\n",
    "                mask3 = (xqj < 1) | (xqj >= nxq - 1)\n",
    "                xqf[mask1] = 0\n",
    "                xqg[mask2] = 0\n",
    "                xqh[mask3] = 0\n",
    "\n",
    "                temp1 = wq2[:, tuple((np.minimum(np.maximum(xqj, 1), nxq) - 1).astype(int))] * (xqf + xqh)\n",
    "                temp2 = wq2[:, tuple((np.minimum(np.maximum(xqj + 1, 1), nxq) - 1).astype(int))] * (xqg + xqh)\n",
    "                temp3 = (wq2[:, tuple((np.minimum(np.maximum(xqj - 1, 1), nxq) - 1).astype(int))] + \n",
    "                         wq2[:, tuple((np.minimum(np.maximum(xqj + 2, 1), nxq) - 1).astype(int))]) * xqh\n",
    "\n",
    "                wq2 = temp1 + temp2 - temp3\n",
    "                \n",
    "            # Use quadratic interpolation in slope axis\n",
    "            if ((sq2[-1] - sq2[0]) / (sqrange)) > nr[15]:\n",
    "                # If range has shrunk by < nr(16), leave the slope axis unchanged\n",
    "                sq2 = sqi.copy()  # Copy the old slope axis\n",
    "                wqup -= 1  # Update flag\n",
    "            else:\n",
    "                # Do quadratic interpolation\n",
    "                if LOG:\n",
    "                    print(f'N={int(iq)}:{int(nresq[iq])}, interpolate s: s({sqi[0]:.2g},{sqi[-1]:.2g})->({sq2[0]:.2g},{sq2[-1]:.2g})')\n",
    "\n",
    "                sqf = (sq2 - sqi[0]) / (sqi[1] - sqi[0])\n",
    "                sqj = np.ceil(sqf).astype(int)\n",
    "                sqf = sqj - sqf\n",
    "                sqg = 1 - sqf\n",
    "                sqh = 0.25 * sqf * sqg # Quadratic coefficient\n",
    "                sqf[(sqj <= 0) | (sqj > nsq)] = 0\n",
    "                sqg[(sqj < 0) | (sqj >= nsq)] = 0\n",
    "                sqh[(sqj < 1) | (sqj >= nsq-1)] = 0\n",
    "                wq2 = wq2[min(np.maximum(sqj, 1), nsq)-1, :] * np.tile(sqf+sqh, (nxq,1)).T + \\\n",
    "                      wq2[min(np.maximum(sqj+1, 1), nsq)-1, :] * np.tile(sqg+sqh, (nxq,1)).T - \\\n",
    "                      (wq2[min(np.maximum(sqj-1, 1), nsq)-1, :] + wq2[min(np.maximum(sqj+2, 1), nsq)-1, :]) * np.tile(sqh, (nxq,1)).T\n",
    "\n",
    "        if wqup > 0:\n",
    "            wq2 = np.maximum(wq2 - np.max(wq2), wfl) # turn back into a normalized, clipped vector\n",
    "            wq2 = wq2.ravel(order=\"F\")\n",
    "            sqi = sq2.copy() # update slope (or log slope) values in PDF\n",
    "            xqi = xq2.copy() # update SRT values of the pdf array\n",
    "            wqi = wq2.copy() # log pdf array\n",
    "            sq[:, iq-1] = sqi[0] # save new s axis (log slope or slope)\n",
    "            xq[:, iq-1] = xqi[:,0] # save new x axis (SRT)\n",
    "            wq[:, iq-1] = wqi.copy() # save log-pdf\n",
    "        if nr[10]:\n",
    "            sqis = np.exp(sqi) / qr[3, iq-1] # inverse std dev of gaussian (proportional to slope)\n",
    "        else:\n",
    "            sqis = sqi / qr[3, iq-1] # inverse std dev of gaussian (proportional to slope)\n",
    "            \n",
    "        if r is not None: # CHECK THAT THIS ACHIEVES THE SAME RESULT\n",
    "            if nres >= res.shape[0]:  # ensure there is space for a new result\n",
    "                res = np.vstack((res, np.zeros((nres, 7))))\n",
    "            nres += 1  # increment the total number of results\n",
    "            nresq[0,iq-1] += 1  # increment the number of results for this model\n",
    "            res[nres - 1, :3] = np.array([float(iq-1), x, float(r==True)])  # save the latest result\n",
    "            xmm[:, iq-1] = [min(x, xmm[0, iq-1]), max(x, xmm[1, iq-1])]  # update min/max probe values\n",
    "            \n",
    "            # warning: xmm is not exactly like matlab because of numeric precision\n",
    "            hn *= hfact  # increase v_entropy gains to ensure all models get a chance\n",
    "            r0 = r == 0\n",
    "            if nr[9] == 1:\n",
    "                sqis = sqis.ravel()\n",
    "                xqi = xqi.ravel()\n",
    "                wqi = wqi + np.log(r0 + (1 - 2 * r0) *\n",
    "                                   (guess + pscale * \n",
    "                                    (((1 + np.exp((np.outer(sqis, xqi) - xtstd)-np.tile((x*sqis),(int(nxq),1)).T)).ravel(order='F'))**(-1)))) # P(l | r,x)\n",
    "            elif nr[9] == 2:\n",
    "                sqis = sqis.ravel()\n",
    "                xqi = xqi.ravel()\n",
    "                wqi = wqi + np.log(r0 + (1 - 2 * r0) * (guess + pscale * norm.cdf(np.outer(sqis, x) - np.reshape(sqis * xqi - xtstd, (nsxq, 1)))))  # P(l | r,x)\n",
    "            else:\n",
    "                raise ValueError('Unrecognised psychometric model selection')\n",
    "            wq[:, iq-1] = wqi  # save updated probabilities\n",
    "\n",
    "        ewqi = np.exp(wqi - np.max(wqi))             # unnormalized probability vector\n",
    "        ewqi = ewqi / np.sum(ewqi)\n",
    "        wqsx = np.reshape(ewqi, (int(nxq), int(nsq))).T        # normalized probabilities\n",
    "        xqi = xqi.ravel()\n",
    "        sqi = sqi.ravel()\n",
    "        \n",
    "        px = np.sum(wqsx, axis=0)                             # p(x0)\n",
    "        ps = np.sum(wqsx, axis=1)                             # p(s0)\n",
    "        xe = np.dot(px, xqi)                                  # E(x0)\n",
    "        se = np.dot(ps, sqi)                                  # E(s0)\n",
    "        \n",
    "        pxpk, xm = np.max(px), np.argmax(px)\n",
    "        if xm > 0 and xm < nxq-1:                           # use quadratic interpolation in log prob if possible\n",
    "            log_px = np.log(px[xm-1:xm+2])\n",
    "            xm2 = v_quadpeak(log_px)\n",
    "            xm2 = xm2[1]\n",
    "            xm = xm + xm2 - 1\n",
    "        xm = (2 - xm) * xqi[0] + (xm - 1) * xqi[1]             # marginal mode(x0)\n",
    "        \n",
    "        pspk, sm = max((ps[i], i) for i in range(int(nsq)))\n",
    "        if sm > 0 and sm < nsq-1:                           # use quadratic interpolation in log prob if possible\n",
    "            log_ps = np.log(ps[sm-1:sm+2])\n",
    "            sm2 = v_quadpeak(log_ps)\n",
    "            sm2 = sm2[1]\n",
    "            sm = sm + sm2 - 1\n",
    "        sm = (2 - sm) * sqi[0] + (sm - 1) * sqi[1]             # marginal mode(s0)\n",
    "                \n",
    "\n",
    "        wqpk, j = max((ewqi[0,i], i) for i in range(int(nsq*nxq)))\n",
    "        i = (j-1) // nsq\n",
    "        j = j - nsq * (i)\n",
    "\n",
    "        if i > 0 and i < nxq-1 and j > 0 and j < nsq-1:             # use quadratic interpolation in log prob if possible\n",
    "            wqi_3x3 = wqi[0,((np.tile(np.arange(j-1,j+2).reshape((-1,1)), (1,3))+nsq*np.tile(np.arange(i-1,i+2),(3,1))).ravel(order='F')).astype(int)].reshape((-1,np.arange(i-1,i+2).size), order='F')\n",
    "            ji = v_quadpeak(wqi_3x3)\n",
    "            ji = ji[1]\n",
    "            i = i + ji[1] - 1\n",
    "            j = j + ji[0] - 1\n",
    "        xj = (2 - i) * xqi[0] + (i - 1) * xqi[1]  # joint mode  x\n",
    "        sj = (2 - j) * sqi[0] + (j - 1) * sqi[1]  # joint mode: s\n",
    "        \n",
    "        xv = np.dot(px, (xqi ** 2)) - xe ** 2  # Var(x0)\n",
    "        sv = np.dot(ps.T, sqi ** 2) - se ** 2  # Var(s0)\n",
    "        xqi = xqi.ravel()\n",
    "        sqi = sqi.ravel()\n",
    "        sxv = np.dot(ewqi, (np.tile(sqi - se, int(nxq)) *\n",
    "                              np.tile(xqi.T - xe, (int(nsq),1)).ravel(order=\"F\")))  # Cov(s0*x0)\n",
    "        mq[:, iq-1, 0] = np.array([xe, se])  # save means\n",
    "        mq[:, iq-1, 1] = np.array([xj.item(), sj.item()])  # save joint mode\n",
    "        mq[:, iq-1, 2] = np.array([xm.item(), sm.item()])  # save marginal modes\n",
    "\n",
    "        vq[:, iq-1] = np.array([xv, sxv.item(), sv])  # save covariance matrix\n",
    "        xh = np.dot(px, np.log(px).T) * (xqi[0] - xqi[1])  # differential v_entropy h(x0)\n",
    "        sh = np.dot(ps.T, np.log(ps)) * (sqi[0] - sqi[1])  # differential v_entropy h(s0)\n",
    "        \n",
    "        # if not plotting\n",
    "        if po == '':\n",
    "            if nr[8] == 1:  # cost function: 1=variance, 2=v_entropy\n",
    "                res[nres-1, 3:7] = [xe, se, xv, sv]  # save info for plotting history\n",
    "            elif nr[8] == 2:\n",
    "                res[nres-1, 3:7] = [xe, se, xh, sh]  # find the minimum of cost function\n",
    "        \n",
    "        ################################################################################\n",
    "        ##### Calculate ROBUST ESTIMATES ###############################################\n",
    "        ################################################################################\n",
    "        if robust==True:\n",
    "            if nr[18]==0:\n",
    "                mr=mq.copy()\n",
    "                vr=vq.copy()\n",
    "            elif nresr==nres:\n",
    "                mr=mqr.copy()\n",
    "                vr=vqr.copy()\n",
    "            else:\n",
    "#                 print(res) \n",
    "                for jq in range(nresq.size):\n",
    "                    if any(res[nresr:nres+1,0]==jq):\n",
    "                        guessj=pr[2,jq]\n",
    "                        pscalej=qr[0,jq]\n",
    "                        xtstdj=qr[2,jq]\n",
    "                        xqj=xq[:,jq]\n",
    "                        sqj=sq[:,jq]\n",
    "#                         print(guessj,pscalej,xtstdj,xqj,sqj)\n",
    "        \n",
    "        \n",
    "        if len(xz[iq-1])==0:\n",
    "            print('Have not implement free SNR estimation yet, matlab lines 678-709')\n",
    "        else:\n",
    "            xzi = xz[iq-1]  # xzi is the list of available probe SNRs\n",
    "            if len(xzi) <= nxh:  # use all available probe SNRs if there are not too many\n",
    "                xt = xzi\n",
    "            else:\n",
    "                ixt = np.argmin(np.abs(xzi - xe))  # find the closest one to xe ** not necessarily optimum ***\n",
    "                ixt = max(0, min(len(xzi) - nxh, ixt - int((1 + nxh) / 2)))  # arrange symmetrically around xt\n",
    "                xt = xzi[int(ixt):int(min(ixt + nxh, len(xzi)))]\n",
    "\n",
    "        nxhp = len(xt)  # xt are the potential probe SNRs\n",
    "        # Now find the probe value that minimizes the expected value of the cost function\n",
    "        # In the following: l = parameters of psychometric function, x = the probe SNR and r = the probe result\n",
    "        if nr[9] == 1:\n",
    "            prt = guess + pscale*((1 + np.exp(np.tile((np.outer(sqis, xqi) - xtstd).ravel(order=\"F\"),(int(nxhp),1))-\n",
    "                                              np.outer(np.tile(sqis,int(nxq)),(xt)).T))**(-1)).T  # P(r=1 | l,x)\n",
    "        elif nr[9] == 2:\n",
    "            prt = guess + pscale*norm.cdf(np.tile(sqis, (nxq, 1)) @ xt - np.tile(np.reshape(sqis @ xqi - xtstd, (nsxq, 1)), (1, nxhp)))  # P(r=1 | l,x)\n",
    "        \n",
    "        \n",
    "\n",
    "        wqt = np.tile(ewqi, (int(nxhp),1)).T\n",
    "        hminr = np.zeros((2, 1))  # space for minimum expected cost function for each r0\n",
    "        hminj = np.zeros((nxhp, 1))  # space for minimum expected cost function for each x0\n",
    "        \n",
    "        if nr[17]:  # if doing look 2-ahead\n",
    "            pl1 = prt * wqt  # posterior prob given success = p(l | x0,r0=1) unnormalized\n",
    "            pl0 = wqt - pl1  # posterior prob given failure = p(l | x0,r0=0) unnormalized\n",
    "            pr0 = np.sum(pl1, axis=0)  # p(r0=1 | x0)=Sum{P(r0=1 | l,x0)*P(l)} [note each column of wqt is normalized] (row vector)\n",
    "\n",
    "#             print((pl0 / np.tile(1 - pr0, (int(nsxq), 1)))[0,:])\n",
    "            plxr = np.reshape(np.concatenate((pl0 / np.tile(1 - pr0, (int(nsxq), 1)), \n",
    "                                              pl1 / np.tile(pr0, (int(nsxq), 1))), axis=1), (int(nsxq), int(nxhp), 2), order=\"F\")  # posterior prob p(l | x0,r0) column-normalized\n",
    "            nx0 = nxhp  # outer loop for each x0\n",
    "            nr0 = 2  # inner loop for each r0\n",
    "            \n",
    "        else:  # if only doing look 1-ahead\n",
    "            nx0 = 0  # only execute outer loop once\n",
    "            nr0 = 0  # only execute inner loop once\n",
    "            pr0 = -1  # dummy value (used at end of outer loop)\n",
    "\n",
    "        hx2 = np.zeros((nx0, nxhp, nr0)) # space for square array of expected cost functions (for possible plotting only)\n",
    "\n",
    "        for j in range(nx0): # loop for each possible probe SNR, x0, (or only once is look-1-ahead)\n",
    "            for jr in range(nr0): # loop for each possible test result, r0=jr-1 (or only once is look-1-ahead)\n",
    "                if nr[17]: # if doing look 2-ahead\n",
    "                    wqt = np.tile(plxr[:, j, jr], (nxhp,1)).T # posterior prob p(l | x0=xt(j),r0=jr-1) column-normalized\n",
    "                \n",
    "                pl1 = prt * wqt # posterior prob given success = p(l | x,r=1) unnormalized\n",
    "                pl0 = wqt - pl1 # posterior prob given failure = p(l | x,r=0) unnormalized\n",
    "                prh = np.atleast_2d(np.sum(pl1, axis=0)) # p(r | x)=Sum{P(r | l,x)*P(l)} [note each column of wqtjr is normalized] (row vector)\n",
    "\n",
    "                pl1 = pl1 / np.tile(prh, (int(nsxq), 1)) # posterior prob given success = p(l | x,r=1) normalized\n",
    "                pl0 = pl0 / np.tile(1 - prh, (int(nsxq), 1)) # posterior prob given failure = p(l | x,r=0) normalized\n",
    "                px1 = np.sum(np.reshape(pl1, (int(nsq), int(nxq), -1), order=\"F\"), axis=0) # p(x0 | x,r=1)\n",
    "                px0 = np.sum(np.reshape(pl0, (int(nsq), int(nxq), -1), order=\"F\"), axis=0) # p(x0 | x,r=0)\n",
    "                ps1 = np.sum(np.reshape(pl1, (int(nsq), int(nxq), -1), order=\"F\"), axis=1) # p(s0 | x,r=1)\n",
    "                ps0 = np.sum(np.reshape(pl0, (int(nsq), int(nxq), -1), order=\"F\"), axis=1) # p(s0 | x,r=0)\n",
    "                xqi = np.atleast_2d(xqi)\n",
    "                sqi = np.atleast_2d(sqi)\n",
    "                \n",
    "                xet1 = np.dot(xqi, px1) # E(x0 | x,r=1)\n",
    "                xvt1 = np.dot(xqi**2, px1) - xet1**2 # Var(x0 | x,r=1)\n",
    "                xet0 = np.dot(xqi, px0) # E(x0 | x,r=0)\n",
    "                xvt0 = np.dot(xqi**2, px0) - xet0**2 # Var(x0 | x,r=0)\n",
    "                xvt = xvt1 * prh + xvt0 * (1 - prh) # E(Var(x0 | x ))\n",
    "\n",
    "                set1 = np.dot(sqi, ps1) # E(s0 | x,r=1)\n",
    "                svt1 = np.dot(sqi**2, ps1) - set1**2 # Var(s0 | x,r=1)\n",
    "                set0 = np.dot(sqi, ps0) # E(s0 | x,r=0)\n",
    "                svt0 = np.dot(sqi**2, ps0) - set0**2\n",
    "                svt = svt1*prh+svt0*(1-prh)\n",
    "\n",
    "                xht1 = np.atleast_2d(np.sum(np.log(px1)*px1,0))\n",
    "                xht0 = np.atleast_2d(np.sum(np.log(px0)*px0,0))\n",
    "                xht = (xht1 * prh + xht0 * (1 - prh)) * (xqi[:,0] - xqi[:,1])  # h(x0 | x)\n",
    "                sht1 = np.sum(np.log(ps1) * ps1, axis=0)  # -H(s0 | x,r=1)\n",
    "                sht0 = np.sum(np.log(ps0) * ps0, axis=0)  # -H(s0 | x,r=0)\n",
    "                sht = (sht1 * prh + sht0 * (1 - prh)) * (sqi[:,0] - sqi[:,1])  # h(s0 | x)\n",
    "\n",
    "                if nr[8] == 1:  # cost function: 1=variance, 2=v_entropy\n",
    "                    hx = (xvt + nr[3] * svt) / (1 + nr[3])  # expected cost function for each possible test SNR\n",
    "                elif nr[8] == 2:\n",
    "                    hx = (xht + nr[3] * sht) / (1 + nr[3])  # expected cost function for each possible test SNR\n",
    "                hx2[j, :, jr] = hx  # save expected cost function for possible plotting\n",
    "                hminr[jr], ix = np.min(hx), np.argmin(hx)  # find the minimum of cost function for each value of r (0 or 1)\n",
    "            hminj[j] = (1 - pr0[j]) * hminr[0] + pr0[j] * hminr[1]\n",
    "        if nr[17]==1:\n",
    "            hminr[0], ix = np.min(hminj), np.argmin(hminj)\n",
    "        xn[iq-1] = xt[ix]\n",
    "        if nr[8]==1:\n",
    "            hn[iq-1] = (xv + nr[3]*sv)/((1+nr[3]))-hminr[0]\n",
    "        elif nr[8]==2:\n",
    "            hn[iq-1] = (xh + nr[3]*sh)/((1+nr[3]))-hminr[0]\n",
    "            \n",
    "        ################################################################################\n",
    "        ################################################################################\n",
    "        ##### IMPLEMENT PLOTTING #######################################################\n",
    "        ################################################################################\n",
    "        ################################################################################\n",
    "    if iq != 0:\n",
    "        # now select the appropriate model to probe next\n",
    "        hnmax, ii = np.max(hn), np.argmax(hn)         # choose model with the biggest expected decrease\n",
    "        xx = xn[ii]\n",
    "        m, v = mq.copy(), vq.copy()\n",
    "        if nr[10]:    # if using log-slope\n",
    "            m[1,:,:] = np.exp(m[1, :, :])  # convert to real slope\n",
    "            v[1,:] = v[1,:] * m[1, :, 0]  # correct the covariance\n",
    "            v[2,:] = v[2,:] * m[1, :, 0]**2\n",
    "    else: \n",
    "#         print('do rest of iq equals to 0')\n",
    "        xx = pr\n",
    "        ii = nr\n",
    "        m = res[0:nres, :]\n",
    "        m[:,0]+=1\n",
    "#         if not nargout:\n",
    "#             # print them if no output arguments to call\n",
    "#             fid = LOG + (LOG == 0)  # use standard out if LOG==0\n",
    "#             pdesc = ['Threshold', 'Miss prob', 'Guess Prob', 'Min SNR', 'Max SNR', 'Min Slope', 'Max Slope']\n",
    "#             print('\\n*********\\nModel-specific Parameters\\n', file=LOG)\n",
    "#             for i in range(7):\n",
    "#                 print(f'{i + 1:4d}) {pdesc[i]}: ', end='', file=LOG)\n",
    "#                 if xx.shape[1] > 1:\n",
    "#                     print(', '.join([f'{xx[i, j]:.5g}' for j in range(xx.shape[1] - 1)]) + ', ', end='', file=LOG)\n",
    "#                 print(f'{xx[i, xx.shape[1] - 1]:.5g}', file=LOG)\n",
    "#             qdesc = ['nx  SNR values in PDF',\n",
    "#                      'ns  Slope values in PDF',\n",
    "#                      'nh  Probe SNR values to evaluate',\n",
    "#                      'cs  Weighting of slope relative to SRT in cost function',\n",
    "#                      'dh  Min step size in dB for probe SNRs',\n",
    "#                      'sl  Min slope at threshold',\n",
    "#                      'kp  Std deviations of the pdfs to keep',\n",
    "#                      'hg  Amount to grow expected gains in ni trials',\n",
    "#                      'cf  Cost function',\n",
    "#                      'pm  Psychometric model',\n",
    "#                      'lg  Use log slope as parameter',\n",
    "#                      'pm  Prior std devs in semi-width',\n",
    "#                      'pf  Integrated probability floor',\n",
    "#                      'ts  Number of std devs to explore',\n",
    "#                      'dp  Max shift in probe value',\n",
    "#                      'it  Grid interpolation threshold',\n",
    "#                      'at  Grid boundary tolerance',\n",
    "#                      'la  Look 2-ahead when choosing probe',\n",
    "#                      'op  Oulier probability threshold',\n",
    "#                      'rx  min grid shrink factor']\n",
    "#             qoptf = [9, 10]  # fields with options\n",
    "#             qoptval = [['variance', 'entropy'],\n",
    "#                        ['logistic', 'cumulative gaussian']]\n",
    "#             print('\\nShared Parameters\\n', file=LOG)\n",
    "#             for i in range(len(nr)):\n",
    "#                 print(f'{i + 1:4d}) {qdesc[i]}: ', end='', file=LOG)\n",
    "#                 j = next((index for index, value in enumerate(qoptf) if value == i), None)\n",
    "#                 if j is not None:\n",
    "#                     print(f'{nr[i]}={qoptval[j][nr[i]]}', file=LOG)\n",
    "#                 else:\n",
    "#                     print(f'{nr[i]:.5g}', file=LOG)\n",
    "#             print('\\n', file=LOG)\n",
    "\n",
    "    if iq !=0:\n",
    "        return xx, ii+1, m, v\n",
    "    else:\n",
    "        return xx, ii+1, m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a400085e",
   "metadata": {},
   "source": [
    "### run demo_psychest\n",
    "\n",
    "First run the model estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b63d2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "modelp = np.array([[0.5, 0.5], [0.01, 0.04], [0, 0.1], [-20, -20], [20,20], [0,0], [0.5,0.5]])\n",
    "# modelp = np.array([[0.5], [0.01], [0], [-20], [20], [0], [0.5]])\n",
    "\n",
    "nmodels=modelp.shape[1]\n",
    "availsnr=np.linspace(-10, 10, 21).T\n",
    "\n",
    "# print(availsnr)\n",
    "\n",
    "[snr, __, __, __]=v_psycest(-nmodels, modelp=modelp, availsnr=availsnr)\n",
    "truemodel=np.array([[0.5], [0.0], [0.1], [0.01], [0], [1]])\n",
    "print(availsnr)\n",
    "nt = 10\n",
    "listofresponses = np.array([[1], [0], [0], [0], [0], [0], [1], [1], [1], [1], [1], [0], [1], [1], [0],[1],[0]])\n",
    "ii=1\n",
    "for i in range(nt):\n",
    "#     [response, __] = v_psychofunc('r',truemodel,np.array([snr]));\n",
    "    response = np.array([[bool(listofresponses[i])]])\n",
    "#     response = bool(listofresponses[i])\n",
    "    print('snr: ',snr, 'response: ',response, 'model: ', ii)\n",
    "    [snr, ii, m, v] = v_psycest(ii, probesnr=snr, response=response, robust=True);\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d599535",
   "metadata": {},
   "source": [
    "Now do the plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa0379",
   "metadata": {},
   "outputs": [],
   "source": [
    "[p,q,msr]=v_psycest(0)\n",
    "thresh=np.array([p[0,0]])\n",
    "# True distribution parameters\n",
    "truesrt, _ = v_psychofunc('i',truemodel,thresh)         # SNR that gives response probability of thresh\n",
    "slope1, _ = v_psychofunc('',truemodel,truesrt+0.01)\n",
    "slope2, _ = v_psychofunc('',truemodel,truesrt-0.01)\n",
    "trueslope=(slope1-slope2)/0.02;\n",
    "trueintercepts=truesrt+([0,1]-thresh)/trueslope;    # SNRs at which the tangent at (truesrt,thresh) intercepts p=0 and p=1\n",
    "\n",
    "srtax = np.atleast_2d(np.linspace(-20,20,100))\n",
    "trueplot = v_psychofunc('',truemodel,srtax.T)\n",
    "print(msr)\n",
    "plt.plot(trueplot[1], trueplot[0], label='True model');\n",
    "for i in range(nmodels):\n",
    "    newmsr=msr[np.where(msr[:,0]==i)]\n",
    "    thresh=np.array([p[0,i]])                                        # point on psychometric function that we were estimating\n",
    "    estplot = v_psychofunc('',np.array([[p[0,i]], [newmsr[-1,3]], [np.exp(newmsr[-1,4])], [p[1,i]], [p[2,i]], [q[9]]], dtype=object),srtax.T)\n",
    "\n",
    "    plt.plot(estplot[1], estplot[0], label=\"Estimated model {}\".format(i))\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e3931",
   "metadata": {},
   "source": [
    "# Class implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd307e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class basie_estimator():\n",
    "#     def __init__(self, nmodels, **kwargs):\n",
    "#         self.initialise(nmodels, **kwargs)\n",
    "    def get_next_model(self, **kwargs):\n",
    "        mq=self.mq\n",
    "        vq=self.vq\n",
    "        xn=self.xn\n",
    "        hn=self.hn\n",
    "        nr=self.nr\n",
    "        if 'robust' in kwargs:\n",
    "            robust = kwargs.get('robust')\n",
    "        else:\n",
    "            robust = False\n",
    "        \n",
    "        # now select the appropriate model to probe next\n",
    "        hnmax, ii = np.max(hn), np.argmax(hn)         # choose model with the biggest expected decrease\n",
    "        xx = xn[ii]\n",
    "        m, v = mq.copy(), vq.copy()\n",
    "        if nr[10]:    # if using log-slope\n",
    "            m[1,:,:] = np.exp(m[1, :, :])  # convert to real slope\n",
    "            v[1,:] = v[1,:] * m[1, :, 0]  # correct the covariance\n",
    "            v[2,:] = v[2,:] * m[1, :, 0]**2\n",
    "        \n",
    "        if robust==True:\n",
    "            mqr=self.mqr\n",
    "            vqr=self.vqr\n",
    "            return xx, ii+1, m, v, mqr, vqr\n",
    "        else:\n",
    "            return xx, ii+1, m, v\n",
    "        \n",
    "    def initialise(self, iq, **kwargs):\n",
    "#             global wq, xq, sq, nr, pr, qr, mq, vq, xn, hn, hfact, xz, res, nres, nresq, xmm, mq0, pq0, wfl, sqmin, LOG, mqr, vqr, nresr, xlim\n",
    "        # ---------- check kwargs ---------- #\n",
    "        if 'modelp' not in kwargs:\n",
    "            warnings.warn('No model parameters found. Using defaults')\n",
    "            x = None\n",
    "        else:\n",
    "            x = kwargs.get('modelp')\n",
    "        \n",
    "        if 'basiep' not in kwargs:\n",
    "            warnings.warn('No basie parameters found. Using defaults')\n",
    "            r = None\n",
    "        else:\n",
    "            r = kwargs.get('basiep')\n",
    "        \n",
    "        if 'availsnr' not in kwargs:\n",
    "            warnings.warn('No available snr found. Using defaults')\n",
    "            xp = None\n",
    "        else:\n",
    "            xp = kwargs.get('availsnr')\n",
    "            \n",
    "        if 'logfile' in kwargs:\n",
    "            LOG = kwargs.get('logfile')\n",
    "            with open(LOG, 'a') as f:\n",
    "                f.write(\"******************************\\n\")\n",
    "                f.write(\"psycest Initialization: {}\\n\".format(str(datetime.datetime.now())))\n",
    "                f.write(\"******************************\\n\")\n",
    "        else:\n",
    "            LOG = None\n",
    "        \n",
    "        # initialise number of models\n",
    "        ni = iq                 # number of models\n",
    "        nres = 0                 # total number of probe-results so far\n",
    "        nresq = np.atleast_2d(np.zeros((1,ni)))    # number of probe-results for each model\n",
    "        res = np.atleast_2d(np.zeros(7))        # array for saving results [expands as needed]\n",
    "        \n",
    "        \n",
    "        # initialise model specific parameters\n",
    "        pr = np.tile([0.5, 0.04, 0.1, -20, 20, 0, 0.5], (ni, 1)).T         # default parameters\n",
    "        if x is not None:\n",
    "            if isinstance(x, list):\n",
    "                x=np.tile(x, (1, 1)).T\n",
    "            if 7 not in np.shape(x):\n",
    "                raise ValueError('Requires 7 modelp')\n",
    "            if len(np.shape(x))==1:\n",
    "                x = np.atleast_2d(x)\n",
    "            if np.shape(x)[1]==7 and np.shape(x)[0]!=7:\n",
    "                x = x.T\n",
    "            if x.shape[1] > 1:\n",
    "                if x.shape[1] > ni:\n",
    "                    raise ValueError(\"initialization parameter argument has too many columns\")\n",
    "                pr[:x.shape[0], :x.shape[1]] = x\n",
    "            else:\n",
    "                pr[:x.shape[0], :] = np.tile(x, (1, ni))\n",
    "        \n",
    "        # initialise parameters common to all models\n",
    "        nr = np.array([40, 21, 30, 1, 0.2, 0.02, 4, 1.3, 2, 1, 1, 1, 0.0001, 2, 10, 0.5, 0.1, 1, 0.01, 0.5])                      # default parameter values\n",
    "        nrf = np.array(['nx', 'ns', 'nh', 'cs', 'dh', 'sl', 'kp', 'hg', 'cf', 'pm', 'lg', 'pp', 'pf', 'ts', 'dp', 'it', 'at', 'la', 'op', 'rx']).T     # parameter field names\n",
    "        numnr = len(nr)\n",
    "        if r is not None: # replace defaults with any parameter values specified in the call\n",
    "            if isinstance(r, dict):\n",
    "                for k, v in r.items():\n",
    "                    mk = [x == k for x in nrf]\n",
    "                    if any(mk):\n",
    "                        nr[mk] = v\n",
    "            else:\n",
    "                nr[:min(numnr, len(r))] = r[:min(numnr, len(r))] # if parameters are specified as a vector, copy them across\n",
    "            nr[:3] = np.round(nr[:3])             # first three parameters must be integers\n",
    "        pr[5, :] = np.maximum(pr[5, :], nr[5])             # low limit of slope in prob/dB\n",
    "        nxq = nr[0]\n",
    "        nsq = nr[1]\n",
    "        nsxq = nxq * nsq\n",
    "        xq = np.linspace(pr[3], pr[4], int(nxq))\n",
    "\n",
    "        if nr[10]:  # if log slope\n",
    "            sqmin = np.log(nr[5])  # low limit for axis\n",
    "#             sq = np.array((np.arange(1-nsq, 1,1)*(np.log(pr[6, :]) - np.log(np.maximum(pr[5, :], nr[5])))/(nsq-1)) + np.log(pr[6, :]),ndmin=2).T\n",
    "            sq = np.outer((np.arange(1-nsq, 1,1)),(np.log(pr[6, :]) \n",
    "                                                   - np.log(np.maximum(pr[5, :], nr[5]))))/(nsq-1) + np.tile(np.log(pr[6, :]),(int(nsq),1))\n",
    "        else:\n",
    "            sqmin = nr[5].copy()  # low limit for axis\n",
    "            sq = np.array((np.arange(1-nsq, 1,1)*(pr[6, :] - np.maximum(pr[5, :], nr[5]))/(nsq-1)) + pr[6, :],ndmin=2).T\n",
    "            \n",
    "        mq0 = np.vstack((np.mean(xq, axis=0), np.mean(sq, axis=0)))  # find mean of prior\n",
    "        pq0 = -2 * nr[11]**2 * np.power(np.vstack((xq[-1, :] - xq[0, :], sq[-1, :] - sq[0, :])), -2)  # scale factor for prior distribution\n",
    "        wq = (np.tile((pq0[1, 0] * np.power((sq[:, 0] - mq0[1, 0]), 2)), (int(nxq),1)) + np.tile(pq0[0, 0] * np.power((xq[:, 0] - mq0[0, 0]), 2),(int(nsq),1)).T) # log probs of prior (same for all models)\n",
    "\n",
    "        wfl = np.log(nr[12] / nsxq)  # floor relative to peak of wq array\n",
    "        wq = np.tile(wq.ravel(), (ni,1)).T  # initialize to +-q.pp std deviations of gaussian prior\n",
    "        qr = np.zeros((5, ni))\n",
    "        \n",
    "        qr[0, :] = 1 - pr[1, :] - pr[2, :]  # prob range covered by cumulative gaussian\n",
    "        \n",
    "        \n",
    "        if np.any(qr[0, :] <= 0):\n",
    "            i = np.argmin(qr[0, :])\n",
    "            raise ValueError(f\"Model {i}: guess prob ({pr[2, i]:.2f}) + miss prob ({pr[1, i]:.2f}) is >=1\")\n",
    "        qr[1, :] = (pr[0, :] - pr[2, :])/qr[0, :]  # cumulative gaussian probability at threshold\n",
    "        if np.any(np.abs(qr[1, :] - 0.5) >= 0.5):\n",
    "            i = np.argmax(np.abs(qr[1, :] - 0.5))\n",
    "            raise ValueError(f\"Model {i}: target SRT threshold ({pr[0, i]:.2f}) must lie in the range guess prob ({pr[2, i]:.2f}) to (1-miss prob) ({1-pr[1, :]:.2f})\")\n",
    "\n",
    "        if nr[9] == 1:  # logistic model\n",
    "            qr[2,:] = np.log(qr[1,:]/(1-qr[1,:]))\n",
    "            qr[3,:] = qr[0,:]*qr[1,:]*(1-qr[1,:])\n",
    "        elif nr[9] == 2:  # cumulative gaussian model\n",
    "            qr[2,:]= -erfcinv(2 * qr[1,:]) * np.sqrt(2)\n",
    "            qr[3,:] = qr[0,:]*norm.pdf(qr[2,:])\n",
    "        else:\n",
    "            raise ValueError('Unrecognised psychometric model selection')\n",
    "\n",
    "        if nr[9] < 1 or nr[9] > 2:\n",
    "            raise ValueError('Unrecognised cost function option')\n",
    "        mq = np.tile(mq0.T, (3, 1, 1)).T  # initial means, joint mode and marginal mode all are equal\n",
    "        vq = np.vstack((np.var(xq, axis=0, ddof=0), np.zeros((1, ni)), np.var(sq, axis=0, ddof=0)))  # initial variances (actually ignores prior probs)\n",
    "        mqr = mq.copy()  # robust means and modes\n",
    "        vqr = vq.copy()  # robust variances\n",
    "        nresr = 0  # robust calculation time\n",
    "        xlim = np.vstack((-np.inf * np.ones(ni), np.inf * np.ones(ni)))  # SNR limits for outliers\n",
    "        hn = np.inf * np.ones(ni)  # very high initial cost function\n",
    "        hfact = nr[7] ** (1 / ni)  # growth factor to ensure that no model is neglected for too long\n",
    "        xn = mq0[0, :].copy()  # start at mean value\n",
    "        xmm = np.vstack((xn, xn))  # min/max of probe values for each model\n",
    "        \n",
    "        # initialise available snrs\n",
    "        if xp is not None and len(xp) > 0:\n",
    "            if xp.ndim>1:\n",
    "                xz = np.atleast_2d(xp)\n",
    "            else:\n",
    "                xz = np.tile(np.expand_dims(xp, axis=0), (ni, 1)).tolist()  # else replicate for each model\n",
    "            for i in range(ni):\n",
    "                j = np.argmin(np.abs(np.array(xz[i]) - mq0[0, i]))  # select the closest available probe to the mean\n",
    "                xn[i] = xz[i][j]\n",
    "        else:\n",
    "            xz = [None] * ni  # make empty list\n",
    "            \n",
    "        self.wq=wq\n",
    "        self.xq=xq\n",
    "        self.sq=sq\n",
    "        self.nr=nr\n",
    "        self.pr=pr\n",
    "        self.qr=qr\n",
    "        self.mq=mq\n",
    "        self.vq=vq\n",
    "        self.xn=xn\n",
    "        self.hn=hn\n",
    "        self.hfact=hfact\n",
    "        self.xz=xz\n",
    "        self.res=res\n",
    "        self.nres=nres\n",
    "        self.nresq=nresq\n",
    "        self.xmm=xmm\n",
    "        self.mq0=mq0\n",
    "        self.pq0=pq0\n",
    "        self.wfl=wfl\n",
    "        self.sqmin=sqmin\n",
    "        self.LOG=LOG\n",
    "        self.mqr=mqr\n",
    "        self.vqr=vqr\n",
    "        self.nresr=nresr\n",
    "        self.xlim=xlim\n",
    "        \n",
    "        return self.get_next_model()\n",
    "        \n",
    "    def update(self, iq, **kwargs):\n",
    "        wq=self.wq\n",
    "        xq=self.xq\n",
    "        sq=self.sq\n",
    "        nr=self.nr\n",
    "        pr=self.pr\n",
    "        qr=self.qr\n",
    "        mq=self.mq\n",
    "        vq=self.vq\n",
    "        xn=self.xn\n",
    "        hn=self.hn\n",
    "        hfact=self.hfact\n",
    "        xz=self.xz\n",
    "        res=self.res\n",
    "        nres=self.nres\n",
    "        nresq=self.nresq\n",
    "        xmm=self.xmm\n",
    "        mq0=self.mq0\n",
    "        pq0=self.pq0\n",
    "        wfl=self.wfl\n",
    "        sqmin=self.sqmin\n",
    "        LOG=self.LOG\n",
    "        mqr=self.mqr\n",
    "        vqr=self.vqr\n",
    "        nresr=self.nresr\n",
    "        xlim=self.xlim\n",
    "        # iq>0 means update or plot model iq\n",
    "        # first check the plotting options\n",
    "        if 'plotopts' in kwargs:\n",
    "            po = kwargs.get('plotopts')\n",
    "        else:\n",
    "            po = ''\n",
    "\n",
    "        if 'probesnr' in kwargs:\n",
    "            x = kwargs.get('probesnr')\n",
    "        else:\n",
    "            x = None\n",
    "\n",
    "        if 'response' in kwargs:\n",
    "            r = kwargs.get('response')\n",
    "            if isinstance(r, bool):\n",
    "                r=np.array([[(r)]])\n",
    "            elif isinstance(r, int) or isinstance(r, float):\n",
    "                r=np.array([[(r=='1')]])\n",
    "        else:\n",
    "            r = None\n",
    "\n",
    "        if 'robust' in kwargs:\n",
    "            robust = kwargs.get('robust')\n",
    "        else:\n",
    "            robust = False\n",
    "\n",
    "        # now get parameters of current model (iq)\n",
    "        nxq = nr[0] # number of snr values\n",
    "        nsq = nr[1] # number of slope values\n",
    "        nxh = nr[2] # number of probe-snr values\n",
    "        nsxq = nxq*nsq # size of log pdf array\n",
    "\n",
    "        thresh = pr[0,iq-1].copy() # target probability at threshold\n",
    "        guess = pr[2,iq-1].copy() # quess rate (1/choices)\n",
    "        pscale = qr[0,iq-1].copy() # prob range left after substracting miss and guess probs\n",
    "        xtstd = qr[2,iq-1].copy() # x position of target in std measure\n",
    "\n",
    "        xqi = xq[:,iq-1] # SRT values of the pdf array\n",
    "        sqi = sq[:,iq-1] # slope (or log slope) values in PDF\n",
    "        wqi = wq[:,iq-1] # log pdf array\n",
    "        mqi = mq[:,iq-1,0] # [xe;se] means\n",
    "        vqi = vq[:,iq-1] # [xv; sxv; sv] covariance matrix\n",
    "\n",
    "        # rescale pdfs if necessary\n",
    "        ssd = np.sqrt(vqi[2])           # std deviation of slope\n",
    "        xsd = np.sqrt(vqi[0])           # std deviation of SRT\n",
    "        # determine range of new grid\n",
    "        xqrange = xqi[-1] - xqi[0]      # range of old SRT grid\n",
    "        sqrange = sqi[-1] - sqi[0]      # range of old slope grid\n",
    "\n",
    "        if nresq[0,iq-1] < 2:               # keep old limits if nresq(iq) < 2\n",
    "            xq2lim = [xqi[0], xqi[-1]]\n",
    "            sq2lim = [sqi[0], sqi[-1]]\n",
    "        else:\n",
    "            # CHECK HERE\n",
    "            xqsemirange = max(nr[6] * xsd, 0.5 * nr[19] * xqrange)\n",
    "            xq2lim = [mqi[0] - xqsemirange, mqi[0] + xqsemirange]\n",
    "            sqsemirange = max(nr[6] * ssd, 0.5 * nr[19] * sqrange)\n",
    "            sq2lim = [max(sqmin, mqi[1] - sqsemirange), mqi[1] + sqsemirange]\n",
    "\n",
    "            if abs(xq2lim[0] - xqi[0]) < nr[16] * xqrange:\n",
    "                xq2lim[0] = xqi[0]\n",
    "            if abs(xq2lim[1] - xqi[-1]) < nr[16] * xqrange:\n",
    "                xq2lim[1] = xqi[-1]\n",
    "\n",
    "            if abs(sq2lim[0] - sqi[0]) < nr[16] * sqrange:\n",
    "                sq2lim[0] = sqi[0]\n",
    "            if abs(sq2lim[1] - sqi[-1]) < nr[16] * sqrange:\n",
    "                sq2lim[1] = sqi[-1]\n",
    "\n",
    "        xq2 = np.linspace(xq2lim[0], xq2lim[1], int(nxq)).reshape(-1, 1) # new x axis values\n",
    "        sq2 = np.linspace(sq2lim[0], sq2lim[1], int(nsq)).reshape(-1, 1) # new s axis values\n",
    "        wqup = 2 # update flag\n",
    "\n",
    "        if xq2[0] < xqi[0] or xq2[-1] > xqi[-1] or sq2[0] < sqi[0] or sq2[-1] > sqi[-1]:\n",
    "#             if extrapolating, recalculate log-pdfs from saved data\n",
    "            if LOG:\n",
    "                print(f'N={iq}:{int(nresq[0,iq-1])}, extrapolate: x({xqi[0]:.2f},{xqi[-1]:.2f})->({xq2[0]},{xq2[-1]}) and s({sqi[0]:.2f},{sqi[-1]:.2f})->({sq2[0]},{sq2[-1]})')\n",
    "\n",
    "            wq2 = (np.tile(pq0[1,iq-1]*(sq2-mq0[1,iq-1])**2, (1,int(nxq))).T + np.tile(pq0[0,iq-1]*(xq2-mq0[0,iq-1])**2, (1,int(nsq)))).T # log probs of prior for model iq\n",
    "            ires = np.where(res[:nres,0] == iq-1)[0] # find the results for this model\n",
    "            sqis = np.exp(sq2)/qr[3,iq-1] if nr[10] else sq2/qr[3,iq-1] # inverse std dev of gaussian (proportional to slope)\n",
    "            for i in range(len(ires)):\n",
    "                j = ires[i]\n",
    "                r0 = res[j,2] == 0\n",
    "                if nr[9] == 1:\n",
    "                    wq2 = wq2 + np.log(r0 + (1 - 2*r0) * (guess + pscale * (1 + np.exp(np.multiply(sqis, xq2.T) - xtstd - np.multiply(sqis, res[j,1])))**(-1))) # P(l | r,x)\n",
    "                elif nr[9] == 2:\n",
    "                    wq2 = wq2 + np.log(r0 + (1 - 2*r0) * (guess + pscale * norm.cdf(np.multiply(sqis, res[j,1]) - np.multiply(sqis, xq2.T) + xtstd))) # P(l | r,x)\n",
    "\n",
    "        else:\n",
    "            # Turn into a normalized, clipped matrix for easy interpolation\n",
    "            wq2 = np.maximum(np.reshape(wqi, (int(nsq), int(nxq))) - np.max(wqi), wfl)\n",
    "            # Use quadratic interpolation in SRT axis\n",
    "            if ((xq2[-1] - xq2[0]) / (xqrange)) > nr[15]:\n",
    "                # If range has shrunk by < nr(16), leave the SRT axis unchanged\n",
    "                xq2 = xqi.copy()  # Copy the old SRT axis\n",
    "                wqup = 1  # Update flag\n",
    "            else:\n",
    "                # Do quadratic interpolation\n",
    "                if LOG:\n",
    "                    print(f'N={iq}:{nresq[0, iq-1]}, interpolate x: x({xqi[0]},{xqi[-1]})->({xq2[0]},{xq2[-1]})')\n",
    "                xqf = (xq2 - xqi[0]) / (xqi[1] - xqi[0])\n",
    "                xqj = np.ceil(xqf).astype(int)\n",
    "                xqf = xqj - xqf\n",
    "                xqg = 1 - xqf\n",
    "                xqh = 0.25 * xqf * xqg  # Quadratic coefficient\n",
    "\n",
    "                mask1 = (xqj <= 0) | (xqj > nxq)\n",
    "                mask2 = (xqj < 0) | (xqj >= nxq)\n",
    "                mask3 = (xqj < 1) | (xqj >= nxq - 1)\n",
    "                xqf[mask1] = 0\n",
    "                xqg[mask2] = 0\n",
    "                xqh[mask3] = 0\n",
    "\n",
    "                temp1 = wq2[:, tuple((np.minimum(np.maximum(xqj, 1), nxq) - 1).astype(int))] * (xqf + xqh)\n",
    "                temp2 = wq2[:, tuple((np.minimum(np.maximum(xqj + 1, 1), nxq) - 1).astype(int))] * (xqg + xqh)\n",
    "                temp3 = (wq2[:, tuple((np.minimum(np.maximum(xqj - 1, 1), nxq) - 1).astype(int))] + \n",
    "                         wq2[:, tuple((np.minimum(np.maximum(xqj + 2, 1), nxq) - 1).astype(int))]) * xqh\n",
    "\n",
    "                wq2 = temp1 + temp2 - temp3\n",
    "\n",
    "            # Use quadratic interpolation in slope axis\n",
    "            if ((sq2[-1] - sq2[0]) / (sqrange)) > nr[15]:\n",
    "                # If range has shrunk by < nr(16), leave the slope axis unchanged\n",
    "                sq2 = sqi.copy()  # Copy the old slope axis\n",
    "                wqup -= 1  # Update flag\n",
    "            else:\n",
    "                # Do quadratic interpolation\n",
    "                if LOG:\n",
    "                    print(f'N={int(iq)}:{int(nresq[iq])}, interpolate s: s({sqi[0]:.2g},{sqi[-1]:.2g})->({sq2[0]:.2g},{sq2[-1]:.2g})')\n",
    "\n",
    "                sqf = (sq2 - sqi[0]) / (sqi[1] - sqi[0])\n",
    "                sqj = np.ceil(sqf).astype(int)\n",
    "                sqf = sqj - sqf\n",
    "                sqg = 1 - sqf\n",
    "                sqh = 0.25 * sqf * sqg # Quadratic coefficient\n",
    "                sqf[(sqj <= 0) | (sqj > nsq)] = 0\n",
    "                sqg[(sqj < 0) | (sqj >= nsq)] = 0\n",
    "                sqh[(sqj < 1) | (sqj >= nsq-1)] = 0\n",
    "                wq2 = wq2[min(np.maximum(sqj, 1), nsq)-1, :] * np.tile(sqf+sqh, (nxq,1)).T + \\\n",
    "                      wq2[min(np.maximum(sqj+1, 1), nsq)-1, :] * np.tile(sqg+sqh, (nxq,1)).T - \\\n",
    "                      (wq2[min(np.maximum(sqj-1, 1), nsq)-1, :] + wq2[min(np.maximum(sqj+2, 1), nsq)-1, :]) * np.tile(sqh, (nxq,1)).T\n",
    "\n",
    "        if wqup > 0:\n",
    "            wq2 = np.maximum(wq2 - np.max(wq2), wfl) # turn back into a normalized, clipped vector\n",
    "            wq2 = wq2.ravel(order=\"F\")\n",
    "            sqi = np.atleast_2d(sq2.copy()) # update slope (or log slope) values in PDF\n",
    "            xqi = xq2.copy() # update SRT values of the pdf array\n",
    "            wqi = wq2.copy() # log pdf array\n",
    "            sq[:, iq-1] = sqi[:,0] # save new s axis (log slope or slope)\n",
    "            xq[:, iq-1] = xqi[:,0] # save new x axis (SRT)\n",
    "            wq[:, iq-1] = wqi.copy() # save log-pdf\n",
    "        if nr[10]:\n",
    "            sqis = np.exp(sqi) / qr[3, iq-1] # inverse std dev of gaussian (proportional to slope)\n",
    "        else:\n",
    "            sqis = sqi / qr[3, iq-1] # inverse std dev of gaussian (proportional to slope)\n",
    "\n",
    "        if r is not None: # CHECK THAT THIS ACHIEVES THE SAME RESULT\n",
    "            if nres >= res.shape[0]:  # ensure there is space for a new result\n",
    "                res = np.vstack((res, np.zeros((nres, 7))))\n",
    "            nres += 1  # increment the total number of results\n",
    "            nresq[0,iq-1] += 1  # increment the number of results for this model\n",
    "            res[nres - 1, :3] = np.array([float(iq-1), x, float(r==True)])  # save the latest result\n",
    "            xmm[:, iq-1] = [min(x, xmm[0, iq-1]), max(x, xmm[1, iq-1])]  # update min/max probe values\n",
    "\n",
    "            # warning: xmm is not exactly like matlab because of numeric precision\n",
    "            hn *= hfact  # increase v_entropy gains to ensure all models get a chance\n",
    "            r0 = r == 0\n",
    "            if nr[9] == 1:\n",
    "                sqis = sqis.ravel()\n",
    "                xqi = xqi.ravel()\n",
    "                wqi = wqi + np.log(r0 + (1 - 2 * r0) *\n",
    "                                   (guess + pscale * \n",
    "                                    (((1 + np.exp((np.outer(sqis, xqi) - xtstd)-np.tile((x*sqis),(int(nxq),1)).T)).ravel(order='F'))**(-1)))) # P(l | r,x)\n",
    "            elif nr[9] == 2:\n",
    "                sqis = sqis.ravel()\n",
    "                xqi = xqi.ravel()\n",
    "                wqi = wqi + np.log(r0 + (1 - 2 * r0) * (guess + pscale * norm.cdf(np.outer(sqis, x) - np.reshape(sqis * xqi - xtstd, (nsxq, 1)))))  # P(l | r,x)\n",
    "            else:\n",
    "                raise ValueError('Unrecognised psychometric model selection')\n",
    "            wq[:, iq-1] = wqi  # save updated probabilities\n",
    "\n",
    "        ewqi = np.exp(wqi - np.max(wqi))             # unnormalized probability vector\n",
    "        ewqi = ewqi / np.sum(ewqi)\n",
    "        wqsx = np.reshape(ewqi, (int(nxq), int(nsq))).T        # normalized probabilities\n",
    "        xqi = xqi.ravel()\n",
    "        sqi = sqi.ravel()\n",
    "\n",
    "        px = np.sum(wqsx, axis=0)                             # p(x0)\n",
    "        ps = np.sum(wqsx, axis=1)                             # p(s0)\n",
    "        xe = np.dot(px, xqi)                                  # E(x0)\n",
    "        se = np.dot(ps, sqi)                                  # E(s0)\n",
    "\n",
    "        pxpk, xm = np.max(px), np.argmax(px)\n",
    "        if xm > 0 and xm < nxq-1:                           # use quadratic interpolation in log prob if possible\n",
    "            log_px = np.log(px[xm-1:xm+2])\n",
    "            xm2 = v_quadpeak(log_px)\n",
    "            xm2 = xm2[1]\n",
    "            xm = xm + xm2 - 1\n",
    "        xm = (2 - xm) * xqi[0] + (xm - 1) * xqi[1]             # marginal mode(x0)\n",
    "\n",
    "        pspk, sm = max((ps[i], i) for i in range(int(nsq)))\n",
    "        if sm > 0 and sm < nsq-1:                           # use quadratic interpolation in log prob if possible\n",
    "            log_ps = np.log(ps[sm-1:sm+2])\n",
    "            sm2 = v_quadpeak(log_ps)\n",
    "            sm2 = sm2[1]\n",
    "            sm = sm + sm2 - 1\n",
    "        sm = (2 - sm) * sqi[0] + (sm - 1) * sqi[1]             # marginal mode(s0)\n",
    "\n",
    "        wqpk, j = max((ewqi[0,i], i) for i in range(int(nsq*nxq)))\n",
    "        i = (j-1) // nsq\n",
    "        j = j - nsq * (i)\n",
    "\n",
    "        if i > 0 and i < nxq-1 and j > 0 and j < nsq-1:             # use quadratic interpolation in log prob if possible\n",
    "            wqi_3x3 = wqi[0,((np.tile(np.arange(j-1,j+2).reshape((-1,1)), (1,3))+nsq*np.tile(np.arange(i-1,i+2),(3,1))).ravel(order='F')).astype(int)].reshape((-1,np.arange(i-1,i+2).size), order='F')\n",
    "            ji = v_quadpeak(wqi_3x3)\n",
    "            ji = ji[1]\n",
    "            i = i + ji[1] - 1\n",
    "            j = j + ji[0] - 1\n",
    "        xj = (2 - i) * xqi[0] + (i - 1) * xqi[1]  # joint mode  x\n",
    "        sj = (2 - j) * sqi[0] + (j - 1) * sqi[1]  # joint mode: s\n",
    "\n",
    "        xv = np.dot(px, (xqi ** 2)) - xe ** 2  # Var(x0)\n",
    "        sv = np.dot(ps.T, sqi ** 2) - se ** 2  # Var(s0)\n",
    "        xqi = xqi.ravel()\n",
    "        sqi = sqi.ravel()\n",
    "        sxv = np.dot(ewqi, (np.tile(sqi - se, int(nxq)) *\n",
    "                              np.tile(xqi.T - xe, (int(nsq),1)).ravel(order=\"F\")))  # Cov(s0*x0)\n",
    "        mq[:, iq-1, 0] = np.array([xe, se])  # save means\n",
    "        mq[:, iq-1, 1] = np.array([xj.item(), sj.item()])  # save joint mode\n",
    "        mq[:, iq-1, 2] = np.array([xm.item(), sm.item()])  # save marginal modes\n",
    "\n",
    "        vq[:, iq-1] = np.array([xv, sxv.item(), sv])  # save covariance matrix\n",
    "        xh = np.dot(px, np.log(px).T) * (xqi[0] - xqi[1])  # differential v_entropy h(x0)\n",
    "        sh = np.dot(ps.T, np.log(ps)) * (sqi[0] - sqi[1])  # differential v_entropy h(s0)\n",
    "\n",
    "        # if not plotting\n",
    "        if po == '':\n",
    "            if nr[8] == 1:  # cost function: 1=variance, 2=v_entropy\n",
    "                res[nres-1, 3:7] = [xe, se, xv, sv]  # save info for plotting history\n",
    "            elif nr[8] == 2:\n",
    "                res[nres-1, 3:7] = [xe, se, xh, sh]  # find the minimum of cost function\n",
    "\n",
    "        ################################################################################\n",
    "        ##### Calculate ROBUST ESTIMATES ###############################################\n",
    "        ################################################################################\n",
    "        if robust==True:\n",
    "            if nr[18]==0:\n",
    "                mr=mq.copy()\n",
    "                vr=vq.copy()\n",
    "            elif nresr==nres:\n",
    "                mr=mqr.copy()\n",
    "                vr=vqr.copy()\n",
    "            else:\n",
    "#                 print(res) \n",
    "                for jq in range(nresq.size):\n",
    "                    if any(res[nresr:nres+1,0]==jq):\n",
    "                        guessj=pr[2,jq]\n",
    "                        pscalej=qr[0,jq]\n",
    "                        xtstdj=qr[2,jq]\n",
    "                        xqj=xq[:,jq]\n",
    "                        sqj=sq[:,jq]\n",
    "                        \n",
    "                        xej=mq[0,jq,0]\n",
    "                        sej=mq[1,jq,0]\n",
    "                        resj=res[res[:,0]==jq,:]\n",
    "                        if nr[10]==1:\n",
    "                            sqisj=np.exp(sej)/qr[3,jq]\n",
    "                        else:\n",
    "                            sqisj=sej/qr[3,jq]\n",
    "                        \n",
    "                        if nr[9]==1:\n",
    "                            xlim[1,jq]=xej-(xtstdj+np.log(nr[18]/(pscalej-nr[18])))/sqisj\n",
    "                        elif nr[9]==2:\n",
    "                            xlim[1,jq]=xej-(-erfcinv(2*((pscalej-nr[18])/pscalej))*np.sqrt(2)-xtstdj)/sqisj\n",
    "                            \n",
    "                        mou=np.logical_and(resj[:,1]>=xlim[1,jq] ,resj[:,2]==0)\n",
    "                        if nr[19]>guessj:\n",
    "                            if nr[9]==1:\n",
    "                                xlim[0,jq]=xej-(xtstdj+np.log(pscalej/(nr[18]-guessj)-1))/sqisj\n",
    "                            elif nr[9]==2:\n",
    "                                xlim[0,jq]=xej+(-erfcinv(2*((pscale-nr[18])/pscalej))*np.sqrt(2)-xtstdj)/sqisj\n",
    "                            mou=np.logical_or(mou, np.logical_and(resj[:,1]<=xlim[0,jq], resj[:,2]==1))\n",
    "                        if any(mou):\n",
    "                            if nr[10]==1:\n",
    "                                sqisj=np.exp(sqj)/qr[3,jq]\n",
    "                            else:\n",
    "                                sqisj=sqj/qr[3,jq]\n",
    "                                \n",
    "                            \n",
    "                            wqj=np.tile(pqo[1,jq]*(sqj-mq0[1,jq])**2,(int(nxq),1))+np.tile(pqo[0,jq]*(xqj-mq0[0,jq])**2,(int(nsq),1))\n",
    "\n",
    "                            if nr[9]==1:\n",
    "                                sqisj = sqisj.ravel()\n",
    "                                xqj=xqj.ravel()\n",
    "                                for j in np.where(mou==0):\n",
    "                                    r0=(resj[j,2]==0)\n",
    "                                    wqj=wqj+np.log(r0+(1-2*r0)*\n",
    "                                                   (guessj+pscalej*\n",
    "                                                    (((1+np.exp((np.outer(sqisj,xqj)-xtstdj)-np.tile(resj[j,1]*sqisj,(int(nxq),1)).T)).ravel(order='F'))**(-1))))\n",
    "                            elif nr[9]==2:\n",
    "                                for j in np.where(mou==0):\n",
    "                                    r0=(resj[j,2]==0)\n",
    "                                    wqj=wqj+np.log(r0+(1-2*r0)*(guessj+pscalej*norm.cdf(np.tile(sqisj,(int(nxq),1))\n",
    "                                                                                       *resj[j,1]-\n",
    "                                                                                       sqisj*xqj.T+xtstdj)))\n",
    "                            wqj=wqj[:].copy()\n",
    "                            ewqj=np.exp(wqj-np.max(wqj))\n",
    "                            ewqj=ewqj/np.sum(ewqj)\n",
    "                            wqsxr=np.reshape(ewqj, (int(nsq),int(nxq)), order=\"F\")\n",
    "                            pxr=np.sum(wqsxr, axis=0)\n",
    "                            psr=np.sum(wqsxr, axis=1)\n",
    "                            xer=pxr*xqj\n",
    "                            ser=psr.T*sqj\n",
    "                            [pxpk,xmr]=np.max(pxr), np.argmax(pxr)\n",
    "                            if xmr>0 and xnr<nxq-1:\n",
    "                                log_px = np.log(px[xmr-1:xmr+2])\n",
    "                                xm2 = v_quadpeak(log_px)\n",
    "                                xm2 = xm2[1]\n",
    "                                xmr = xmr + xm2 - 1\n",
    "                            xmr = (2 - xmr) * xqj[0] + (xmr - 1) * xqj[1]\n",
    "                            [pspk, smr]=np.max(psr), np.argmax(psr)\n",
    "                            if smr>0 and snr<nsq-1:\n",
    "                                log_px = np.log(px[smr-1:smr+2])\n",
    "                                sm2 = v_quadpeak(log_px)\n",
    "                                sm2 = sm2[1]\n",
    "                                smr = smr + sm2 - 1\n",
    "                            smr = (2 - smr) * sqj[0] + (smr - 1) * sqj[1]\n",
    "                            \n",
    "                            wqpk, j = max((ewqj[0,i], i) for i in range(int(nsq*nxq)))\n",
    "                            i = (j-1) // nsq\n",
    "                            j = j - nsq * (i)\n",
    "\n",
    "                            if i > 0 and i < nxq-1 and j > 0 and j < nsq-1:             # use quadratic interpolation in log prob if possible\n",
    "                                wqi_3x3 = wqj[0,((np.tile(np.arange(j-1,j+2).reshape((-1,1)), (1,3))+nsq*np.tile(np.arange(i-1,i+2),(3,1))).ravel(order='F')).astype(int)].reshape((-1,np.arange(i-1,i+2).size), order='F')\n",
    "                                ji = v_quadpeak(wqi_3x3)\n",
    "                                ji = ji[1]\n",
    "                                i = i + ji[1] - 1\n",
    "                                j = j + ji[0] - 1\n",
    "                            xjr = (2 - i) * xqj[0] + (i - 1) * xqj[1]  # joint mode  x\n",
    "                            sjr = (2 - j) * sqj[0] + (j - 1) * sqj[1]  # joint mode: s\n",
    "\n",
    "                            xvr = np.dot(pxr, (xqj ** 2)) - xer ** 2  # Var(x0)\n",
    "                            sv = np.dot(psr.T, sqj ** 2) - ser ** 2  # Var(s0)\n",
    "                            xqj = xqj.ravel()\n",
    "                            sqj = sqj.ravel()\n",
    "                            sxvr = np.dot(ewqj, (np.tile(sqj - ser, int(nxq)) *\n",
    "                                                  np.tile(xqj.T - xer, (int(nsq),1)).ravel(order=\"F\")))  # Cov(s0*x0)\n",
    "                            mqr[:, jq, 0] = np.array([xer, ser])  # save means\n",
    "                            mqr[:, jq, 1] = np.array([xjr.item(), sjr.ritem()])  # save joint mode\n",
    "                            mqr[:, jq, 2] = np.array([xmr.item(), smr.item()])  # save marginal modes\n",
    "\n",
    "                            vqr[:, jq] = np.array([xvr, sxvr.item(), svr])  # save covariance matrix\n",
    "                        else:\n",
    "                            mqr[:,jq,:]=mq[:,jq,:].copy()\n",
    "                            vqr[:,jq]=vq[:,jq].copy()\n",
    "                            \n",
    "        if len(xz[iq-1])==0:\n",
    "            print('Have not implement free SNR estimation yet, matlab lines 678-709')\n",
    "        else:\n",
    "            xzi = xz[iq-1]  # xzi is the list of available probe SNRs\n",
    "            if len(xzi) <= nxh:  # use all available probe SNRs if there are not too many\n",
    "                xt = xzi\n",
    "            else:\n",
    "                ixt = np.argmin(np.abs(xzi - xe))  # find the closest one to xe ** not necessarily optimum ***\n",
    "                ixt = max(0, min(len(xzi) - nxh, ixt - int((1 + nxh) / 2)))  # arrange symmetrically around xt\n",
    "                xt = xzi[int(ixt):int(min(ixt + nxh, len(xzi)))]\n",
    "\n",
    "        nxhp = len(xt)  # xt are the potential probe SNRs\n",
    "        # Now find the probe value that minimizes the expected value of the cost function\n",
    "        # In the following: l = parameters of psychometric function, x = the probe SNR and r = the probe result\n",
    "        if nr[9] == 1:\n",
    "            prt = guess + pscale*((1 + np.exp(np.tile((np.outer(sqis, xqi) - xtstd).ravel(order=\"F\"),(int(nxhp),1))-\n",
    "                                              np.outer(np.tile(sqis,int(nxq)),(xt)).T))**(-1)).T  # P(r=1 | l,x)\n",
    "        elif nr[9] == 2:\n",
    "            prt = guess + pscale*norm.cdf(np.tile(sqis, (nxq, 1)) @ xt - np.tile(np.reshape(sqis @ xqi - xtstd, (nsxq, 1)), (1, nxhp)))  # P(r=1 | l,x)\n",
    "\n",
    "        wqt = np.tile(ewqi, (int(nxhp),1)).T\n",
    "        hminr = np.zeros((2, 1))  # space for minimum expected cost function for each r0\n",
    "        hminj = np.zeros((nxhp, 1))  # space for minimum expected cost function for each x0\n",
    "\n",
    "        if nr[17]:  # if doing look 2-ahead\n",
    "            pl1 = prt * wqt  # posterior prob given success = p(l | x0,r0=1) unnormalized\n",
    "            pl0 = wqt - pl1  # posterior prob given failure = p(l | x0,r0=0) unnormalized\n",
    "            pr0 = np.sum(pl1, axis=0)  # p(r0=1 | x0)=Sum{P(r0=1 | l,x0)*P(l)} [note each column of wqt is normalized] (row vector)\n",
    "\n",
    "#             print((pl0 / np.tile(1 - pr0, (int(nsxq), 1)))[0,:])\n",
    "            plxr = np.reshape(np.concatenate((pl0 / np.tile(1 - pr0, (int(nsxq), 1)), \n",
    "                                              pl1 / np.tile(pr0, (int(nsxq), 1))), axis=1), (int(nsxq), int(nxhp), 2), order=\"F\")  # posterior prob p(l | x0,r0) column-normalized\n",
    "            nx0 = nxhp  # outer loop for each x0\n",
    "            nr0 = 2  # inner loop for each r0\n",
    "\n",
    "        else:  # if only doing look 1-ahead\n",
    "            nx0 = 0  # only execute outer loop once\n",
    "            nr0 = 0  # only execute inner loop once\n",
    "            pr0 = -1  # dummy value (used at end of outer loop)\n",
    "\n",
    "        hx2 = np.zeros((nx0, nxhp, nr0)) # space for square array of expected cost functions (for possible plotting only)\n",
    "\n",
    "        for j in range(nx0): # loop for each possible probe SNR, x0, (or only once is look-1-ahead)\n",
    "            for jr in range(nr0): # loop for each possible test result, r0=jr-1 (or only once is look-1-ahead)\n",
    "                if nr[17]: # if doing look 2-ahead\n",
    "                    wqt = np.tile(plxr[:, j, jr], (nxhp,1)).T # posterior prob p(l | x0=xt(j),r0=jr-1) column-normalized\n",
    "\n",
    "                pl1 = prt * wqt # posterior prob given success = p(l | x,r=1) unnormalized\n",
    "                pl0 = wqt - pl1 # posterior prob given failure = p(l | x,r=0) unnormalized\n",
    "                prh = np.atleast_2d(np.sum(pl1, axis=0)) # p(r | x)=Sum{P(r | l,x)*P(l)} [note each column of wqtjr is normalized] (row vector)\n",
    "\n",
    "                pl1 = pl1 / np.tile(prh, (int(nsxq), 1)) # posterior prob given success = p(l | x,r=1) normalized\n",
    "                pl0 = pl0 / np.tile(1 - prh, (int(nsxq), 1)) # posterior prob given failure = p(l | x,r=0) normalized\n",
    "                px1 = np.sum(np.reshape(pl1, (int(nsq), int(nxq), -1), order=\"F\"), axis=0) # p(x0 | x,r=1)\n",
    "                px0 = np.sum(np.reshape(pl0, (int(nsq), int(nxq), -1), order=\"F\"), axis=0) # p(x0 | x,r=0)\n",
    "                ps1 = np.sum(np.reshape(pl1, (int(nsq), int(nxq), -1), order=\"F\"), axis=1) # p(s0 | x,r=1)\n",
    "                ps0 = np.sum(np.reshape(pl0, (int(nsq), int(nxq), -1), order=\"F\"), axis=1) # p(s0 | x,r=0)\n",
    "                xqi = np.atleast_2d(xqi)\n",
    "                sqi = np.atleast_2d(sqi)\n",
    "\n",
    "                xet1 = np.dot(xqi, px1) # E(x0 | x,r=1)\n",
    "                xvt1 = np.dot(xqi**2, px1) - xet1**2 # Var(x0 | x,r=1)\n",
    "                xet0 = np.dot(xqi, px0) # E(x0 | x,r=0)\n",
    "                xvt0 = np.dot(xqi**2, px0) - xet0**2 # Var(x0 | x,r=0)\n",
    "                xvt = xvt1 * prh + xvt0 * (1 - prh) # E(Var(x0 | x ))\n",
    "\n",
    "                set1 = np.dot(sqi, ps1) # E(s0 | x,r=1)\n",
    "                svt1 = np.dot(sqi**2, ps1) - set1**2 # Var(s0 | x,r=1)\n",
    "                set0 = np.dot(sqi, ps0) # E(s0 | x,r=0)\n",
    "                svt0 = np.dot(sqi**2, ps0) - set0**2\n",
    "                svt = svt1*prh+svt0*(1-prh)\n",
    "\n",
    "                xht1 = np.atleast_2d(np.sum(np.log(px1)*px1,0))\n",
    "                xht0 = np.atleast_2d(np.sum(np.log(px0)*px0,0))\n",
    "                xht = (xht1 * prh + xht0 * (1 - prh)) * (xqi[:,0] - xqi[:,1])  # h(x0 | x)\n",
    "                sht1 = np.sum(np.log(ps1) * ps1, axis=0)  # -H(s0 | x,r=1)\n",
    "                sht0 = np.sum(np.log(ps0) * ps0, axis=0)  # -H(s0 | x,r=0)\n",
    "                sht = (sht1 * prh + sht0 * (1 - prh)) * (sqi[:,0] - sqi[:,1])  # h(s0 | x)\n",
    "\n",
    "                if nr[8] == 1:  # cost function: 1=variance, 2=v_entropy\n",
    "                    hx = (xvt + nr[3] * svt) / (1 + nr[3])  # expected cost function for each possible test SNR\n",
    "                elif nr[8] == 2:\n",
    "                    hx = (xht + nr[3] * sht) / (1 + nr[3])  # expected cost function for each possible test SNR\n",
    "                hx2[j, :, jr] = hx  # save expected cost function for possible plotting\n",
    "                hminr[jr], ix = np.min(hx), np.argmin(hx)  # find the minimum of cost function for each value of r (0 or 1)\n",
    "            hminj[j] = (1 - pr0[j]) * hminr[0] + pr0[j] * hminr[1]\n",
    "        if nr[17]==1:\n",
    "            hminr[0], ix = np.min(hminj), np.argmin(hminj)\n",
    "        xn[iq-1] = xt[ix]\n",
    "        if nr[8]==1:\n",
    "            hn[iq-1] = (xv + nr[3]*sv)/((1+nr[3]))-hminr[0]\n",
    "        elif nr[8]==2:\n",
    "            hn[iq-1] = (xh + nr[3]*sh)/((1+nr[3]))-hminr[0]\n",
    "            \n",
    "        self.wq=wq\n",
    "        self.xq=xq\n",
    "        self.sq=sq\n",
    "        self.nr=nr\n",
    "        self.pr=pr\n",
    "        self.qr=qr\n",
    "        self.mq=mq\n",
    "        self.vq=vq\n",
    "        self.xn=xn\n",
    "        self.hn=hn\n",
    "        self.hfact=hfact\n",
    "        self.xz=xz\n",
    "        self.res=res\n",
    "        self.nres=nres\n",
    "        self.nresq=nresq\n",
    "        self.xmm=xmm\n",
    "        self.mq0=mq0\n",
    "        self.pq0=pq0\n",
    "        self.wfl=wfl\n",
    "        self.sqmin=sqmin\n",
    "        self.LOG=LOG\n",
    "        self.mqr=mqr\n",
    "        self.vqr=vqr\n",
    "        self.nresr=nresr\n",
    "        self.xlim=xlim\n",
    "        \n",
    "        return self.get_next_model(**kwargs)\n",
    "    \n",
    "    def summary(self):\n",
    "        pr = self.pr\n",
    "        nr = self.nr\n",
    "        res = self.res\n",
    "        nres = self.nres\n",
    "        xx = pr\n",
    "        ii = nr\n",
    "        m = res[0:nres, :]\n",
    "        m[:,0]+=1\n",
    "        return xx, ii+1, m\n",
    "    \n",
    "    def plot(self, po, modeln):\n",
    "        wq=self.wq\n",
    "        xq=self.xq\n",
    "        sq=self.sq\n",
    "        nr=self.nr\n",
    "        pr=self.pr\n",
    "        qr=self.qr\n",
    "        mq=self.mq\n",
    "        vq=self.vq\n",
    "        xn=self.xn\n",
    "        hn=self.hn\n",
    "        hfact=self.hfact\n",
    "        xz=self.xz\n",
    "        res=self.res\n",
    "        nres=self.nres\n",
    "        nresq=self.nresq\n",
    "        xmm=self.xmm\n",
    "        mq0=self.mq0\n",
    "        pq0=self.pq0\n",
    "        wfl=self.wfl\n",
    "        sqmin=self.sqmin\n",
    "        LOG=self.LOG\n",
    "        mqr=self.mqr\n",
    "        vqr=self.vqr\n",
    "        nresr=self.nresr\n",
    "        xlim=self.xlim\n",
    "\n",
    "        if po=='p':\n",
    "            nxq=nr[0]\n",
    "            nsq=nr[1]\n",
    "            wqi=wq[:,modeln-1].copy()\n",
    "            ewqi = np.exp(wqi - np.max(wqi))             # unnormalized probability vector\n",
    "            ewqi = ewqi / np.sum(ewqi)\n",
    "            wqsx = np.reshape(ewqi, (int(nxq), int(nsq))).T\n",
    "            wqpk, j = max((ewqi[i], i) for i in range(int(nsq*nxq)))\n",
    "            px = np.sum(wqsx, axis=0)                             # p(x0)\n",
    "            ps = np.sum(wqsx, axis=1)                             # p(s0)\n",
    "            pxpk, xm = np.max(px), np.argmax(px)\n",
    "            xqi = xq[:,modeln-1] # SRT values of the pdf array\n",
    "            sqi = sq[:,modeln-1] # slope (or log slope) values in PDF\n",
    "            pspk, sm = max((ps[i], i) for i in range(int(nsq)))\n",
    "            axm=[[3, -2], [2, -1]]\n",
    "\n",
    "            xqj=np.concatenate([np.dot(axm, xqi[0:2]), xqi])\n",
    "            sqj=np.concatenate([np.dot(axm, sqi[0:2]), sqi])\n",
    "            a = np.atleast_2d(np.concatenate([np.zeros(2), np.array(px/pxpk)]))\n",
    "            b = np.atleast_2d(np.zeros( int(nxq)+2))\n",
    "            c = np.concatenate([np.atleast_2d(ps/pspk).T, np.zeros((int(nsq),1)), np.array(wqsx/wqpk)], axis=1)\n",
    "            plt.imshow(np.concatenate([a, b, c], axis=0), extent=[xqj[0], xqj[-1], sqj[0], sqj[-1]],\n",
    "                       aspect='auto', origin='lower')\n",
    "#             plt.xticks(5*np.round(np.arange(xqi[0], xqi[-1], 5)/5))\n",
    "            plt.plot(mq[0,modeln-1,0], mq[1,modeln-1,0], 'ko', markerfacecolor='none')\n",
    "            plt.plot(mq[0,modeln-1,2], mq[1,modeln-1,2], 'k^', markerfacecolor='none')\n",
    "            plt.plot(mq[0,modeln-1,1], mq[1,modeln-1,1], 'k*', markerfacecolor='none')\n",
    "            \n",
    "            binwidthx=(xqj[-1]-xqj[0])/(np.shape(np.concatenate([a, b, c], axis=0))[1])\n",
    "            plt.plot(xqj[1]+0.5*binwidthx, mq[1,modeln-1,0], 'wo', markerfacecolor='none')\n",
    "            plt.plot(xqj[1]+0.5*binwidthx, mq[1,modeln-1,2], 'w^', markerfacecolor='none')\n",
    "            plt.plot(xqj[1]+0.5*binwidthx, mq[1,modeln-1,1], 'w*', markerfacecolor='none')\n",
    "            \n",
    "            binwidthy=(sqj[-1]-sqj[0])/(np.shape(np.concatenate([a, b, c], axis=0))[0])\n",
    "            plt.plot(mq[0,modeln-1,0], sqj[1]+0.5*binwidthy, 'wo', markerfacecolor='none')\n",
    "            plt.plot(mq[0,modeln-1,2], sqj[1]+0.5*binwidthy, 'w^', markerfacecolor='none')\n",
    "            plt.plot(mq[0,modeln-1,1], sqj[1]+0.5*binwidthy, 'w*', markerfacecolor='none')\n",
    "            \n",
    "            t=np.linspace(0, 2*math.pi, num=500, endpoint=True)\n",
    "            xcir=np.cos(t)\n",
    "            scir=np.sin(t)\n",
    "            vcir=np.sqrt((vq[2,modeln-1]*xcir**2+vq[0,modeln-1]*scir**2\n",
    "                         -2*vq[1,modeln-1]*xcir*scir)/(vq[0,modeln-1]*vq[2,modeln-1]-vq[1,modeln-1]**2))\n",
    "            plt.plot(mq[0,modeln-1,0]+xcir/vcir, mq[1,modeln-1,0]+scir/vcir, 'w-')\n",
    "            plt.xlabel(f'SNR @ {np.int32(pr[0]*100)[0]}% SRT (dB)')\n",
    "            plt.title('Joint pdf: o mean, * mode, $\\Delta$ marg mode')\n",
    "            if nr[10]:\n",
    "                plt.ylabel('Log psychometric slope at threshold (prob/dB)')\n",
    "            else:\n",
    "                plt.ylabel('Pyschometric slope at threshold (prob/dB)')\n",
    "                \n",
    "        elif po=='c':\n",
    "            idx = np.where(res[:,0]==modeln-1)\n",
    "            print(np.shape(res))\n",
    "            print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dba4bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/06_y3fbd2lsgsl7k3ljyvwlr0000gn/T/ipykernel_84731/3253493651.py:41: UserWarning: No basie parameters found. Using defaults\n",
      "  warnings.warn('No basie parameters found. Using defaults')\n",
      "/var/folders/66/06_y3fbd2lsgsl7k3ljyvwlr0000gn/T/ipykernel_84731/3253493651.py:307: RuntimeWarning: overflow encountered in exp\n",
      "  wq2 = wq2 + np.log(r0 + (1 - 2*r0) * (guess + pscale * (1 + np.exp(np.multiply(sqis, xq2.T) - xtstd - np.multiply(sqis, res[j,1])))**(-1))) # P(l | r,x)\n",
      "/var/folders/66/06_y3fbd2lsgsl7k3ljyvwlr0000gn/T/ipykernel_84731/3253493651.py:307: RuntimeWarning: divide by zero encountered in log\n",
      "  wq2 = wq2 + np.log(r0 + (1 - 2*r0) * (guess + pscale * (1 + np.exp(np.multiply(sqis, xq2.T) - xtstd - np.multiply(sqis, res[j,1])))**(-1))) # P(l | r,x)\n",
      "/var/folders/66/06_y3fbd2lsgsl7k3ljyvwlr0000gn/T/ipykernel_84731/3253493651.py:395: RuntimeWarning: overflow encountered in exp\n",
      "  (((1 + np.exp((np.outer(sqis, xqi) - xtstd)-np.tile((x*sqis),(int(nxq),1)).T)).ravel(order='F'))**(-1)))) # P(l | r,x)\n",
      "/var/folders/66/06_y3fbd2lsgsl7k3ljyvwlr0000gn/T/ipykernel_84731/3253493651.py:594: RuntimeWarning: overflow encountered in exp\n",
      "  prt = guess + pscale*((1 + np.exp(np.tile((np.outer(sqis, xqi) - xtstd).ravel(order=\"F\"),(int(nxhp),1))-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snr:  0.0 response:  [[ True]] model:  1\n",
      "snr:  -8.0 response:  [[False]] model:  1\n",
      "snr:  -3.0 response:  [[False]] model:  1\n",
      "snr:  1.0 response:  [[False]] model:  1\n",
      "snr:  6.0 response:  [[False]] model:  1\n",
      "snr:  10.0 response:  [[ True]] model:  1\n",
      "snr:  8.0 response:  [[ True]] model:  1\n",
      "snr:  5.0 response:  [[ True]] model:  1\n",
      "snr:  1.0 response:  [[ True]] model:  1\n",
      "snr:  -3.0 response:  [[False]] model:  1\n",
      "snr:  2.0 response:  [[ True]] model:  1\n",
      "snr:  -4.0 response:  [[False]] model:  1\n",
      "snr:  3.0 response:  [[ True]] model:  1\n",
      "snr:  -4.0 response:  [[False]] model:  1\n",
      "snr:  3.0 response:  [[False]] model:  1\n",
      "snr:  6.0 response:  [[ True]] model:  1\n",
      "snr:  -4.0 response:  [[False]] model:  1\n",
      "snr:  5.0 response:  [[ True]] model:  1\n",
      "snr:  -3.0 response:  [[False]] model:  1\n",
      "snr:  4.0 response:  [[ True]] model:  1\n",
      "snr:  -3.0 response:  [[ True]] model:  1\n",
      "snr:  -5.0 response:  [[False]] model:  1\n",
      "snr:  4.0 response:  [[ True]] model:  1\n",
      "snr:  -5.0 response:  [[ True]] model:  1\n",
      "snr:  -8.0 response:  [[False]] model:  1\n",
      "snr:  -7.0 response:  [[False]] model:  1\n",
      "snr:  4.0 response:  [[ True]] model:  1\n",
      "snr:  -6.0 response:  [[False]] model:  1\n",
      "snr:  3.0 response:  [[ True]] model:  1\n",
      "snr:  -5.0 response:  [[False]] model:  1\n",
      "[[ 0.     0.     1.    -8.126 -2.305  3.398  0.488]\n",
      " [ 0.    -8.     0.    -3.306 -2.368  3.259  0.488]\n",
      " [ 0.    -3.     0.    -0.161 -2.156  3.477  0.744]\n",
      " [ 0.     1.     0.     3.638 -2.838  3.448  0.734]\n",
      " [ 0.     6.     0.     8.838 -3.195  4.174  0.481]\n",
      " [ 0.    10.     1.     6.026 -3.076  4.414  0.391]\n",
      " [ 0.     8.     1.     3.997 -2.979  4.141  0.399]\n",
      " [ 0.     5.     1.     2.315 -2.924  3.421  0.444]\n",
      " [ 0.     1.     1.     0.477 -2.985  3.403  0.439]\n",
      " [ 0.    -3.     0.     1.532 -2.89   3.243  0.447]\n",
      " [ 0.     2.     1.     0.352 -2.851  3.157  0.454]\n",
      " [ 0.    -4.     0.     1.021 -2.738  2.303  0.496]\n",
      " [ 0.     3.     1.     0.293 -2.64   2.222  0.506]\n",
      " [ 0.    -4.     0.     0.715 -2.519  1.985  0.552]\n",
      " [ 0.     3.     0.     1.797 -2.774  2.044  0.509]\n",
      " [ 0.     6.     1.     1.369 -2.686  1.977  0.51 ]\n",
      " [ 0.    -4.     0.     1.66  -2.604  1.912  0.507]\n",
      " [ 0.     5.     1.     1.293 -2.521  1.845  0.506]\n",
      " [ 0.    -3.     0.     1.54  -2.445  1.783  0.501]\n",
      " [ 0.     4.     1.     1.209 -2.369  1.72   0.5  ]\n",
      " [ 0.    -3.     1.     0.415 -2.673  1.858  0.486]\n",
      " [ 0.    -5.     0.     0.64  -2.605  1.801  0.481]\n",
      " [ 0.     4.     1.     0.368 -2.542  1.748  0.478]\n",
      " [ 0.    -5.     1.    -0.461 -2.839  1.896  0.47 ]\n",
      " [ 0.    -8.     0.    -0.255 -2.78   1.845  0.464]\n",
      " [ 0.    -7.     0.    -0.078 -2.725  1.799  0.459]\n",
      " [ 0.     4.     1.    -0.316 -2.672  1.754  0.455]\n",
      " [ 0.    -6.     0.    -0.155 -2.621  1.711  0.448]\n",
      " [ 0.     3.     1.    -0.388 -2.574  1.67   0.445]\n",
      " [ 0.    -5.     0.     3.92  -1.772  1.114  0.312]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.   ]]\n",
      "[[ 1.     0.     1.    -8.126 -2.305  3.398  0.488]\n",
      " [ 1.    -8.     0.    -3.306 -2.368  3.259  0.488]\n",
      " [ 1.    -3.     0.    -0.161 -2.156  3.477  0.744]\n",
      " [ 1.     1.     0.     3.638 -2.838  3.448  0.734]\n",
      " [ 1.     6.     0.     8.838 -3.195  4.174  0.481]\n",
      " [ 1.    10.     1.     6.026 -3.076  4.414  0.391]\n",
      " [ 1.     8.     1.     3.997 -2.979  4.141  0.399]\n",
      " [ 1.     5.     1.     2.315 -2.924  3.421  0.444]\n",
      " [ 1.     1.     1.     0.477 -2.985  3.403  0.439]\n",
      " [ 1.    -3.     0.     1.532 -2.89   3.243  0.447]\n",
      " [ 1.     2.     1.     0.352 -2.851  3.157  0.454]\n",
      " [ 1.    -4.     0.     1.021 -2.738  2.303  0.496]\n",
      " [ 1.     3.     1.     0.293 -2.64   2.222  0.506]\n",
      " [ 1.    -4.     0.     0.715 -2.519  1.985  0.552]\n",
      " [ 1.     3.     0.     1.797 -2.774  2.044  0.509]\n",
      " [ 1.     6.     1.     1.369 -2.686  1.977  0.51 ]\n",
      " [ 1.    -4.     0.     1.66  -2.604  1.912  0.507]\n",
      " [ 1.     5.     1.     1.293 -2.521  1.845  0.506]\n",
      " [ 1.    -3.     0.     1.54  -2.445  1.783  0.501]\n",
      " [ 1.     4.     1.     1.209 -2.369  1.72   0.5  ]\n",
      " [ 1.    -3.     1.     0.415 -2.673  1.858  0.486]\n",
      " [ 1.    -5.     0.     0.64  -2.605  1.801  0.481]\n",
      " [ 1.     4.     1.     0.368 -2.542  1.748  0.478]\n",
      " [ 1.    -5.     1.    -0.461 -2.839  1.896  0.47 ]\n",
      " [ 1.    -8.     0.    -0.255 -2.78   1.845  0.464]\n",
      " [ 1.    -7.     0.    -0.078 -2.725  1.799  0.459]\n",
      " [ 1.     4.     1.    -0.316 -2.672  1.754  0.455]\n",
      " [ 1.    -6.     0.    -0.155 -2.621  1.711  0.448]\n",
      " [ 1.     3.     1.    -0.388 -2.574  1.67   0.445]\n",
      " [ 1.    -5.     0.     3.92  -1.772  1.114  0.312]]\n",
      "[[ 1.     0.     1.    -8.126 -2.305  3.398  0.488]\n",
      " [ 1.    -8.     0.    -3.306 -2.368  3.259  0.488]\n",
      " [ 1.    -3.     0.    -0.161 -2.156  3.477  0.744]\n",
      " [ 1.     1.     0.     3.638 -2.838  3.448  0.734]\n",
      " [ 1.     6.     0.     8.838 -3.195  4.174  0.481]\n",
      " [ 1.    10.     1.     6.026 -3.076  4.414  0.391]\n",
      " [ 1.     8.     1.     3.997 -2.979  4.141  0.399]\n",
      " [ 1.     5.     1.     2.315 -2.924  3.421  0.444]\n",
      " [ 1.     1.     1.     0.477 -2.985  3.403  0.439]\n",
      " [ 1.    -3.     0.     1.532 -2.89   3.243  0.447]\n",
      " [ 1.     2.     1.     0.352 -2.851  3.157  0.454]\n",
      " [ 1.    -4.     0.     1.021 -2.738  2.303  0.496]\n",
      " [ 1.     3.     1.     0.293 -2.64   2.222  0.506]\n",
      " [ 1.    -4.     0.     0.715 -2.519  1.985  0.552]\n",
      " [ 1.     3.     0.     1.797 -2.774  2.044  0.509]\n",
      " [ 1.     6.     1.     1.369 -2.686  1.977  0.51 ]\n",
      " [ 1.    -4.     0.     1.66  -2.604  1.912  0.507]\n",
      " [ 1.     5.     1.     1.293 -2.521  1.845  0.506]\n",
      " [ 1.    -3.     0.     1.54  -2.445  1.783  0.501]\n",
      " [ 1.     4.     1.     1.209 -2.369  1.72   0.5  ]\n",
      " [ 1.    -3.     1.     0.415 -2.673  1.858  0.486]\n",
      " [ 1.    -5.     0.     0.64  -2.605  1.801  0.481]\n",
      " [ 1.     4.     1.     0.368 -2.542  1.748  0.478]\n",
      " [ 1.    -5.     1.    -0.461 -2.839  1.896  0.47 ]\n",
      " [ 1.    -8.     0.    -0.255 -2.78   1.845  0.464]\n",
      " [ 1.    -7.     0.    -0.078 -2.725  1.799  0.459]\n",
      " [ 1.     4.     1.    -0.316 -2.672  1.754  0.455]\n",
      " [ 1.    -6.     0.    -0.155 -2.621  1.711  0.448]\n",
      " [ 1.     3.     1.    -0.388 -2.574  1.67   0.445]\n",
      " [ 1.    -5.     0.     3.92  -1.772  1.114  0.312]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.   ]]\n",
      "(32, 7)\n",
      "(array([30, 31]),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "# modelp = np.array([[0.5, 0.5], [0.01, 0.04], [0, 0.1], [-20, -20], [20,20], [0,0], [0.5,0.5]])\n",
    "modelp = np.array([[0.5], [0.01], [0], [-20], [20], [0], [0.5]])\n",
    "\n",
    "nmodels=modelp.shape[1]\n",
    "availsnr=np.linspace(-10, 10, 21).T\n",
    "\n",
    "# print(availsnr)\n",
    "test=basie_estimator()\n",
    "# [snr, __, __, __]=v_psycest(-nmodels, modelp=modelp, availsnr=availsnr)\n",
    "[snr,_,_,_]=test.initialise(1, modelp=modelp, availsnr=availsnr)\n",
    "truemodel=np.array([[0.5], [0.0], [0.1], [0.01], [0], [1]])\n",
    "nt = 30\n",
    "listofresponses = np.array([[1], [0], [0], [0], [0], [0], [1], [1], [1], [1], [1], [0], [1], [1], [0],[1],[0]])\n",
    "ii=1\n",
    "for i in range(nt):\n",
    "    [response, __] = v_psychofunc('r',truemodel,np.array([snr]));\n",
    "#     response = np.array([[bool(listofresponses[i])]])\n",
    "#     response = bool(listofresponses[i])\n",
    "    print('snr: ',snr, 'response: ',response, 'model: ', ii)\n",
    "#     [snr, ii, m, v] = v_psycest(ii, probesnr=snr, response=response, robust=True);\n",
    "    [snr, ii, m, v] =test.update(ii, probesnr=snr, response=response, robust=False)\n",
    "print(test.res)\n",
    "print(test.summary()[2])\n",
    "print(test.res)\n",
    "fig=plt.figure(figsize=(5,4))\n",
    "test.plot('c',1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68abcec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
